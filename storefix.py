from dotenv import load_dotenv
load_dotenv()
import os
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
os.environ["HF_HUB_OFFLINE"] = "0"
os.environ["TRANSFORMERS_OFFLINE"] = "0"
os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY", "sk-FxhjDpv1D62n33JGICef3aVagezAr73GFnoXmSQ4ikMpf9Hb")
os.environ["OPENAI_API_URL"] = os.getenv("OPENAI_API_URL", "https://api.openai-proxy.org/v1")
os.environ["MODEL_NAME"] = os.getenv("MODEL_NAME", "deepseek-chat")
os.environ["DB_PATH"] = os.getenv("DB_PATH", "store.db")

import sqlite3
import json
import hashlib
import fitz
import numpy as np
import faiss
from typing import List, Dict, Optional, Tuple
from datetime import datetime
from sentence_transformers import SentenceTransformer
from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_react_agent
from langchain.tools import Tool
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

class Config:
    """ç³»ç»Ÿé…ç½®ç±»"""
    def __init__(self):
        self.embedding_model = "paraphrase-multilingual-mpnet-base-v2"
        self.llm_model = os.getenv("MODEL_NAME")
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.openai_api_base = os.getenv("OPENAI_API_URL")
        self.pdf_knowledge_dir = "./knowledge_pdfs"
        self.index_dim = 768
        self.top_k = 10
        self.rag_threshold = 0.75  # è°ƒæ•´é˜ˆå€¼
        self.chunk_size = 500
        self.chunk_overlap = 50
        self.cache_expiry = 86400
        self.max_retrieval_docs = 5
        self.max_agent_iterations = 3  # é™åˆ¶Agentè¿­ä»£æ¬¡æ•°

class KnowledgeMatcher:
    """å¢å¼ºçš„çŸ¥è¯†åº“åŒ¹é…å™¨"""
    def __init__(self, config: Config):
        self.config = config
        self.embedder = SentenceTransformer(config.embedding_model)
        self.vectorstore = None
        self._init_knowledge_base()
    
    def _init_knowledge_base(self):
        """åˆå§‹åŒ–ç»Ÿä¸€çŸ¥è¯†åº“"""
        try:
            # åŠ è½½å‘é‡ç´¢å¼• - ä¿®å¤pickleå®‰å…¨é—®é¢˜
            if os.path.exists("vector_db.index"):
                # ä½¿ç”¨ä¸storefix.pyå…¼å®¹çš„åŠ è½½æ–¹å¼
                import faiss
                self.vector_index = faiss.read_index("vector_db.index")
                print("âœ… åŠ è½½å·²æœ‰çŸ¥è¯†åº“å‘é‡ç´¢å¼•")
                
                # åˆ›å»ºLangChainå…¼å®¹çš„å‘é‡å­˜å‚¨
                embeddings = HuggingFaceEmbeddings(model_name=self.config.embedding_model)
                # åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„å‘é‡å­˜å‚¨ç”¨äºLangChainæ¥å£
                self.vectorstore = self._create_langchain_compatible_store(embeddings)
            else:
                print("âš ï¸ çŸ¥è¯†åº“å‘é‡ç´¢å¼•ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œstorefix.pyåŒæ­¥æ•°æ®")
                self.vectorstore = None
        except Exception as e:
            print(f"âŒ åŠ è½½çŸ¥è¯†åº“å¤±è´¥: {e}")
            self.vectorstore = None
    
    def _create_langchain_compatible_store(self, embeddings):
        """åˆ›å»ºLangChainå…¼å®¹çš„å‘é‡å­˜å‚¨"""
        try:
            # ä»SQLiteæ•°æ®åº“è¯»å–çŸ¥è¯†å†…å®¹
            import sqlite3
            conn = sqlite3.connect("knowledge.db")
            cursor = conn.cursor()
            
            cursor.execute("SELECT content, metadata, source FROM knowledge ORDER BY id")
            rows = cursor.fetchall()
            conn.close()
            
            if not rows:
                print("âš ï¸ çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ•°æ®")
                return None
            
            # åˆ›å»ºæ–‡æ¡£åˆ—è¡¨
            documents = []
            for row in rows:
                content, metadata_json, source = row
                metadata = json.loads(metadata_json) if metadata_json else {}
                metadata['source'] = source
                
                documents.append(Document(
                    page_content=content,
                    metadata=metadata
                ))
            
            # åˆ›å»ºå‘é‡å­˜å‚¨
            vectorstore = FAISS.from_documents(documents, embeddings)
            return vectorstore
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºLangChainå…¼å®¹å­˜å‚¨å¤±è´¥: {e}")
            return None
    
    def check_relevance(self, query: str) -> Tuple[bool, float, List[Dict]]:
        """æ£€æŸ¥é—®é¢˜ä¸çŸ¥è¯†åº“çš„ç›¸å…³æ€§"""
        if not self.vectorstore:
            return False, 0.0, []
        
        try:
            # æ£€ç´¢ç›¸å…³æ–‡æ¡£
            docs = self.vectorstore.similarity_search_with_score(query, k=self.config.max_retrieval_docs)
            
            if not docs:
                return False, 0.0, []
            
            # è®¡ç®—å¹³å‡åŒ¹é…åº¦
            scores = [1.0 - score for _, score in docs]
            avg_score = sum(scores) / len(scores)
            max_score = max(scores)
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°é˜ˆå€¼ï¼ˆä½¿ç”¨å¹³å‡åˆ†å’Œæœ€é«˜åˆ†çš„åŠ æƒï¼‰
            relevance_score = (avg_score * 0.7 + max_score * 0.3)
            is_relevant = relevance_score >= self.config.rag_threshold
            
            # æ ¼å¼åŒ–ç»“æœ
            results = []
            for doc, score in docs:
                results.append({
                    "content": doc.page_content,
                    "metadata": doc.metadata,
                    "score": 1.0 - score,
                    "source": doc.metadata.get("source", "unknown")
                })
            
            return is_relevant, relevance_score, results
            
        except Exception as e:
            print(f"âŒ ç›¸å…³æ€§æ£€æŸ¥å¤±è´¥: {e}")
            return False, 0.0, []

class DatabaseAgent:
    """å¢å¼ºçš„æ•°æ®åº“ä¸“ç”¨Agent"""
    def __init__(self, config: Config):
        self.config = config
        self.db_path = "store.db"
        self.llm = ChatOpenAI(
            model_name=self.config.llm_model,
            openai_api_key=self.config.openai_api_key,
            openai_api_base=self.config.openai_api_base,
            temperature=0.3
        )
        self._init_database_schema()
    
    def _init_database_schema(self):
        """åˆå§‹åŒ–æ•°æ®åº“æ¨¡å¼ä¿¡æ¯"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # è·å–è¡¨ç»“æ„ä¿¡æ¯
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
            tables = cursor.fetchall()
            
            self.schema_info = {}
            for table in tables:
                table_name = table[0]
                cursor.execute(f"PRAGMA table_info({table_name});")
                columns = cursor.fetchall()
                self.schema_info[table_name] = [col[1] for col in columns]
            
            conn.close()
            print(f"âœ… æ•°æ®åº“æ¨¡å¼åŠ è½½å®Œæˆï¼ŒåŒ…å« {len(self.schema_info)} ä¸ªè¡¨")
        except Exception as e:
            print(f"âŒ æ•°æ®åº“æ¨¡å¼åŠ è½½å¤±è´¥: {e}")
            self.schema_info = {}
    
    def query(self, question: str, context: str = "") -> str:
        """æ™ºèƒ½æ•°æ®åº“æŸ¥è¯¢"""
        try:
            # åˆ†æé—®é¢˜ç±»å‹
            query_type = self._analyze_query_type(question)
            
            # æ‰§è¡Œç›¸åº”çš„æŸ¥è¯¢
            if query_type == "sales":
                return self._query_sales_data(question, context)
            elif query_type == "inventory":
                return self._query_inventory_data(question, context)
            elif query_type == "supply":
                return self._query_supply_data(question, context)
            elif query_type == "analysis":
                return self._query_analysis_data(question, context)
            else:
                return self._query_general_data(question, context)
                
        except Exception as e:
            return f"âŒ æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {str(e)}"
    
    def _analyze_query_type(self, question: str) -> str:
        """åˆ†ææŸ¥è¯¢ç±»å‹"""
        question_lower = question.lower()
        
        if any(word in question_lower for word in ["é”€å”®", "é”€é‡", "è¥ä¸šé¢", "æ”¶å…¥"]):
            return "sales"
        elif any(word in question_lower for word in ["åº“å­˜", "å­˜è´§", "æ•°é‡", "ä½™é‡"]):
            return "inventory"
        elif any(word in question_lower for word in ["ä¾›åº”", "é…é€", "è¿è¾“", "ç‰©æµ"]):
            return "supply"
        elif any(word in question_lower for word in ["åˆ†æ", "ç»Ÿè®¡", "è¶‹åŠ¿", "å¯¹æ¯”"]):
            return "analysis"
        else:
            return "general"
    
    def _query_sales_data(self, query: str, context: str = "") -> str:
        """æŸ¥è¯¢é”€å”®æ•°æ®"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ ¹æ®æŸ¥è¯¢å†…å®¹åŠ¨æ€ç”ŸæˆSQL
            if "åŒ—äº¬ä¸­å…³æ‘åº—" in query:
                cursor.execute("""
                    SELECT p.product_name, s.monthly_sales, s.month, st.store_name
                    FROM sales s
                    JOIN product p ON s.product_id = p.product_id
                    JOIN store st ON s.store_id = st.store_id
                    WHERE st.store_name = 'åŒ—äº¬ä¸­å…³æ‘åº—'
                    ORDER BY s.month DESC
                    LIMIT 10
                """)
            else:
                cursor.execute("""
                    SELECT st.store_name, p.product_name, s.monthly_sales, s.month
                    FROM sales s
                    JOIN product p ON s.product_id = p.product_id
                    JOIN store st ON s.store_id = st.store_id
                    ORDER BY s.monthly_sales DESC
                    LIMIT 10
                """)
            
            rows = cursor.fetchall()
            conn.close()
            
            if rows:
                result = "ğŸ“Š é”€å”®æ•°æ®åˆ†æï¼š\n"
                for row in rows:
                    if len(row) == 4:
                        result += f"- {row[0]}: {row[1]}ä»¶ï¼Œæ—¥æœŸï¼š{row[2]}\n"
                    else:
                        result += f"- {row[0]}é”€å”®{row[1]}: {row[2]}ä»¶ï¼Œæ—¥æœŸï¼š{row[3]}\n"
                
                # ç»“åˆä¸Šä¸‹æ–‡è¿›è¡Œæ™ºèƒ½åˆ†æ
                if context:
                    result += f"\nğŸ’¡ ç»“åˆçŸ¥è¯†åº“åˆ†æï¼š{self._enhance_with_context(result, context)}"
                
                return result
            else:
                return "âŒ æœªæ‰¾åˆ°ç›¸å…³é”€å”®æ•°æ®"
        except Exception as e:
            return f"âŒ æŸ¥è¯¢é”€å”®æ•°æ®å¤±è´¥: {str(e)}"
    
    def _query_inventory_data(self, query: str, context: str = "") -> str:
        """æŸ¥è¯¢åº“å­˜æ•°æ®"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT p.product_name, i.quantity, w.warehouse_name, i.date
                FROM inventory i
                JOIN product p ON i.product_id = p.product_id
                JOIN warehouse w ON i.warehouse_id = w.warehouse_id
                ORDER BY i.quantity DESC
                LIMIT 10
            """)
            
            rows = cursor.fetchall()
            conn.close()
            
            if rows:
                result = "ğŸ“¦ åº“å­˜æ•°æ®åˆ†æï¼š\n"
                for row in rows:
                    result += f"- {row[0]}: {row[1]}ä»¶ï¼Œä½äº{row[2]}ï¼Œæ—¥æœŸï¼š{row[3]}\n"
                
                # ç»“åˆä¸Šä¸‹æ–‡è¿›è¡Œæ™ºèƒ½åˆ†æ
                if context:
                    result += f"\nğŸ’¡ ç»“åˆçŸ¥è¯†åº“åˆ†æï¼š{self._enhance_with_context(result, context)}"
                
                return result
            else:
                return "âŒ æœªæ‰¾åˆ°ç›¸å…³åº“å­˜æ•°æ®"
        except Exception as e:
            return f"âŒ æŸ¥è¯¢åº“å­˜æ•°æ®å¤±è´¥: {str(e)}"
    
    def _query_supply_data(self, query: str, context: str = "") -> str:
        """æŸ¥è¯¢ä¾›åº”é“¾æ•°æ®"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT w.warehouse_name, st.store_name, p.product_name, s.monthly_supply, s.month
                FROM supply s
                JOIN warehouse w ON s.warehouse_id = w.warehouse_id
                JOIN store st ON s.store_id = st.store_id
                JOIN product p ON s.product_id = p.product_id
                ORDER BY s.monthly_supply DESC
                LIMIT 10
            """)
            
            rows = cursor.fetchall()
            conn.close()
            
            if rows:
                result = "ğŸšš ä¾›åº”é“¾æ•°æ®åˆ†æï¼š\n"
                for row in rows:
                    result += f"- {row[0]}å‘{row[1]}ä¾›åº”{row[2]}: {row[3]}ä»¶ï¼Œæ—¥æœŸï¼š{row[4]}\n"
                
                # ç»“åˆä¸Šä¸‹æ–‡è¿›è¡Œæ™ºèƒ½åˆ†æ
                if context:
                    result += f"\nğŸ’¡ ç»“åˆçŸ¥è¯†åº“åˆ†æï¼š{self._enhance_with_context(result, context)}"
                
                return result
            else:
                return "âŒ æœªæ‰¾åˆ°ç›¸å…³ä¾›åº”é“¾æ•°æ®"
        except Exception as e:
            return f"âŒ æŸ¥è¯¢ä¾›åº”é“¾æ•°æ®å¤±è´¥: {str(e)}"
    
    def _query_analysis_data(self, query: str, context: str = "") -> str:
        """æŸ¥è¯¢åˆ†ææ•°æ®"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ç»¼åˆæ•°æ®åˆ†æ
            cursor.execute("""
                SELECT 
                    p.product_name,
                    SUM(s.monthly_sales) as total_sales,
                    AVG(i.quantity) as avg_inventory,
                    COUNT(DISTINCT st.store_id) as store_count
                FROM product p
                LEFT JOIN sales s ON p.product_id = s.product_id
                LEFT JOIN inventory i ON p.product_id = i.product_id
                LEFT JOIN store st ON s.store_id = st.store_id
                GROUP BY p.product_id
                ORDER BY total_sales DESC
                LIMIT 5
            """)
            
            rows = cursor.fetchall()
            conn.close()
            
            if rows:
                result = "ğŸ“ˆ ç»¼åˆæ•°æ®åˆ†æï¼š\n"
                for row in rows:
                    result += f"- {row[0]}: æ€»é”€é‡{row[1]}ä»¶ï¼Œå¹³å‡åº“å­˜{row[2]:.0f}ä»¶ï¼Œè¦†ç›–{row[3]}å®¶é—¨åº—\n"
                
                # ç»“åˆä¸Šä¸‹æ–‡è¿›è¡Œæ™ºèƒ½åˆ†æ
                if context:
                    result += f"\nğŸ’¡ ç»“åˆçŸ¥è¯†åº“åˆ†æï¼š{self._enhance_with_context(result, context)}"
                
                return result
            else:
                return "âŒ æœªæ‰¾åˆ°ç›¸å…³åˆ†ææ•°æ®"
        except Exception as e:
            return f"âŒ æŸ¥è¯¢åˆ†ææ•°æ®å¤±è´¥: {str(e)}"
    
    def _query_general_data(self, query: str, context: str = "") -> str:
        """é€šç”¨æ•°æ®æŸ¥è¯¢"""
        return "è¯·æä¾›æ›´å…·ä½“çš„æŸ¥è¯¢éœ€æ±‚ï¼Œå¦‚é”€å”®ã€åº“å­˜ã€ä¾›åº”é“¾æˆ–åˆ†æç›¸å…³ä¿¡æ¯ã€‚"
    
    def _enhance_with_context(self, data_result: str, context: str) -> str:
        """ç»“åˆä¸Šä¸‹æ–‡å¢å¼ºæ•°æ®è§£é‡Š"""
        try:
            prompt = PromptTemplate.from_template("""
åŸºäºä»¥ä¸‹æ•°æ®åº“æŸ¥è¯¢ç»“æœå’ŒçŸ¥è¯†åº“ä¸Šä¸‹æ–‡ï¼Œæä¾›æ™ºèƒ½åˆ†æå’Œå»ºè®®ï¼š

æ•°æ®åº“æŸ¥è¯¢ç»“æœï¼š
{data_result}

çŸ¥è¯†åº“ä¸Šä¸‹æ–‡ï¼š
{context}

è¯·ç»“åˆä¸¤è€…æä¾›ï¼š
1. æ•°æ®è¶‹åŠ¿åˆ†æ
2. ä¸šåŠ¡æ´å¯Ÿ
3. ä¼˜åŒ–å»ºè®®

å›ç­”è¦ç®€æ´æ˜äº†ï¼Œä¸è¶…è¿‡100å­—ã€‚
""")
            
            response = self.llm.invoke(prompt.format(data_result=data_result, context=context))
            return response.content
        except Exception as e:
            return f"ä¸Šä¸‹æ–‡åˆ†æå¤±è´¥: {str(e)}"

class PDFAgent:
    """å¢å¼ºçš„PDFæ–‡æ¡£ä¸“ç”¨Agent"""
    def __init__(self, config: Config, pdf_path: str, agent_name: str):
        self.config = config
        self.pdf_path = pdf_path
        self.agent_name = agent_name
        self.llm = ChatOpenAI(
            model_name=self.config.llm_model,
            openai_api_key=self.config.openai_api_key,
            openai_api_base=self.config.openai_api_base,
            temperature=0.3
        )
        self.vectorstore = None
        self._init_pdf_vectorstore()
    
    def _extract_pdf_content(self) -> List[Document]:
        """æå–PDFå†…å®¹"""
        try:
            doc = fitz.open(self.pdf_path)
            documents = []
            
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                text = page.get_text()
                if text.strip():
                    documents.append(Document(
                        page_content=text,
                        metadata={"source": os.path.basename(self.pdf_path), "page": page_num + 1}
                    ))
            
            doc.close()
            return documents
        except Exception as e:
            print(f"âŒ PDFå†…å®¹æå–å¤±è´¥: {e}")
            return []
    
    def _init_pdf_vectorstore(self):
        """åˆå§‹åŒ–PDFå‘é‡å­˜å‚¨"""
        documents = self._extract_pdf_content()
        if not documents:
            print(f"âš ï¸ PDFæ–‡ä»¶ {self.pdf_path} å†…å®¹ä¸ºç©º")
            return
        
        try:
            # æ–‡æœ¬åˆ†å‰²
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=self.config.chunk_size, 
                chunk_overlap=self.config.chunk_overlap
            )
            texts = text_splitter.split_documents(documents)
            
            # åˆ›å»ºå‘é‡å­˜å‚¨
            embeddings = HuggingFaceEmbeddings(model_name=self.config.embedding_model)
            self.vectorstore = FAISS.from_documents(texts, embeddings)
            
            print(f"âœ… {self.agent_name} å‘é‡å­˜å‚¨åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ PDFå‘é‡å­˜å‚¨åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def query(self, question: str, context: str = "") -> str:
        """æ™ºèƒ½PDFå†…å®¹æŸ¥è¯¢"""
        if not self.vectorstore:
            return f"âŒ PDF Agent {self.agent_name} æœªæ­£ç¡®åˆå§‹åŒ–"
        
        try:
            # æ£€ç´¢ç›¸å…³æ–‡æ¡£
            docs = self.vectorstore.similarity_search(question, k=3)
            
            if not docs:
                return f"âŒ åœ¨{self.agent_name}ä¸­æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
            
            # æ„å»ºä¸Šä¸‹æ–‡
            pdf_context = "\n\n".join([doc.page_content for doc in docs])
            
            # ä½¿ç”¨LLMç”Ÿæˆå›ç­”
            prompt = PromptTemplate.from_template("""
åŸºäºä»¥ä¸‹PDFæ–‡æ¡£å†…å®¹å’Œé¢å¤–ä¸Šä¸‹æ–‡ï¼Œå›ç­”é—®é¢˜ï¼š

PDFæ–‡æ¡£å†…å®¹ï¼š
{pdf_context}

é¢å¤–ä¸Šä¸‹æ–‡ï¼š
{context}

é—®é¢˜ï¼š{question}

è¯·æ ¹æ®æ–‡æ¡£å†…å®¹ç»™å‡ºå‡†ç¡®ã€è¯¦ç»†çš„å›ç­”ã€‚å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯´æ˜ã€‚
å¦‚æœæä¾›äº†é¢å¤–ä¸Šä¸‹æ–‡ï¼Œè¯·ç»“åˆä¸¤è€…è¿›è¡Œåˆ†æã€‚
""")
            
            response = self.llm.invoke(prompt.format(
                pdf_context=pdf_context, 
                context=context if context else "æ— é¢å¤–ä¸Šä¸‹æ–‡", 
                question=question
            ))
            return response.content
            
        except Exception as e:
            return f"âŒ PDFæŸ¥è¯¢å¤±è´¥: {str(e)}"

class AgenticRAGSystem:
    """å¢å¼ºçš„Agentic RAGç³»ç»Ÿ"""
    def __init__(self):
        self.config = Config()
        self.knowledge_matcher = KnowledgeMatcher(self.config)
        self.database_agent = DatabaseAgent(self.config)
        self.pdf_agents = {}
        self._init_pdf_agents()
        self.llm = ChatOpenAI(
            model_name=self.config.llm_model,
            openai_api_key=self.config.openai_api_key,
            openai_api_base=self.config.openai_api_base,
            temperature=0.3
        )
        self.query_history = []  # æŸ¥è¯¢å†å²ï¼Œé¿å…é‡å¤å¤„ç†
    
    def _init_pdf_agents(self):
        """åˆå§‹åŒ–PDF Agents"""
        try:
            pdf_files = [f for f in os.listdir(self.config.pdf_knowledge_dir) if f.endswith('.pdf')]
            for i, pdf_file in enumerate(pdf_files[:2]):  # åªå–å‰ä¸¤ä¸ªPDF
                pdf_path = os.path.join(self.config.pdf_knowledge_dir, pdf_file)
                agent_name = f"PDF{i+1}_{os.path.splitext(pdf_file)[0]}"
                self.pdf_agents[agent_name] = PDFAgent(self.config, pdf_path, agent_name)
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–PDF Agentså¤±è´¥: {e}")
    
    def process_query(self, query: str) -> Dict:
        """å¢å¼ºçš„æŸ¥è¯¢å¤„ç†é€»è¾‘"""
        try:
            print(f"ğŸ” æ­£åœ¨åˆ†æé—®é¢˜: {query}")
            
            # æ£€æŸ¥æ˜¯å¦é‡å¤æŸ¥è¯¢
            if query in self.query_history:
                return {
                    "question": query,
                    "answer": "æ£€æµ‹åˆ°é‡å¤æŸ¥è¯¢ï¼Œè¯·æä¾›æ–°çš„é—®é¢˜ã€‚",
                    "source_type": "duplicate",
                    "confidence": 1.0
                }
            
            self.query_history.append(query)
            
            # 1. æ£€æŸ¥çŸ¥è¯†åº“ç›¸å…³æ€§
            is_relevant, relevance_score, knowledge_results = self.knowledge_matcher.check_relevance(query)
            
            print(f"ğŸ“Š çŸ¥è¯†åº“åŒ¹é…åº¦: {relevance_score:.2%}")
            
            # 2. æ”¶é›†æ‰€æœ‰ç›¸å…³ä¿¡æ¯
            all_context = self._gather_all_context(query, knowledge_results)
            
            # 3. æ™ºèƒ½è·¯ç”±å’Œå›ç­”ç”Ÿæˆ
            if is_relevant and knowledge_results:
                print("ğŸ¯ ä½¿ç”¨çŸ¥è¯†åº“ç›´æ¥å›ç­”")
                answer = self._generate_enhanced_answer(query, knowledge_results, all_context)
                return {
                    "question": query,
                    "answer": answer,
                    "source_type": "knowledge_base",
                    "confidence": relevance_score,
                    "relevance_score": relevance_score
                }
            else:
                print("ğŸ¤– ä½¿ç”¨Agentç³»ç»Ÿå›ç­”")
                answer = self._route_to_appropriate_agent(query, all_context)
                
                return {
                    "question": query,
                    "answer": answer,
                    "source_type": "agent_system",
                    "confidence": 0.7,
                    "relevance_score": relevance_score
                }
            
        except Exception as e:
            # 4. å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œä½¿ç”¨LLMç›´æ¥å›ç­”
            print(f"âš ï¸ ä½¿ç”¨LLMç›´æ¥å›ç­”: {e}")
            answer = self._fallback_to_llm(query)
            return {
                "question": query,
                "answer": answer,
                "source_type": "llm_fallback",
                "confidence": 0.5
            }
    
    def _gather_all_context(self, query: str, knowledge_results: List[Dict]) -> str:
        """æ”¶é›†æ‰€æœ‰ç›¸å…³ä¸Šä¸‹æ–‡"""
        context_parts = []
        
        # æ·»åŠ çŸ¥è¯†åº“ç»“æœ
        if knowledge_results:
            context_parts.append("çŸ¥è¯†åº“ä¿¡æ¯ï¼š")
            for result in knowledge_results[:3]:
                context_parts.append(f"- {result['content'][:200]}...")
        
        # æ·»åŠ æ•°æ®åº“ä¿¡æ¯ï¼ˆå¦‚æœé—®é¢˜æ¶‰åŠä¸šåŠ¡æ•°æ®ï¼‰
        if any(keyword in query for keyword in ["é”€å”®", "åº“å­˜", "ä¾›åº”", "é—¨åº—", "æ•°æ®"]):
            try:
                db_context = self.database_agent._query_general_data(query, "")
                if db_context and "è¯·æä¾›æ›´å…·ä½“" not in db_context:
                    context_parts.append(f"æ•°æ®åº“ä¿¡æ¯ï¼š{db_context}")
            except:
                pass
        
        # æ·»åŠ PDFä¿¡æ¯
        pdf_contexts = []
        for agent_name, agent in self.pdf_agents.items():
            try:
                pdf_result = agent.query(query, "")
                if pdf_result and "æœªæ‰¾åˆ°" not in pdf_result:
                    pdf_contexts.append(f"[{agent_name}]: {pdf_result[:300]}...")
            except:
                pass
        
        if pdf_contexts:
            context_parts.append("PDFæ–‡æ¡£ä¿¡æ¯ï¼š")
            context_parts.extend(pdf_contexts)
        
        return "\n\n".join(context_parts) if context_parts else "æ— ç›¸å…³ä¸Šä¸‹æ–‡"
    
    def _generate_enhanced_answer(self, query: str, knowledge_results: List[Dict], all_context: str) -> str:
        """åŸºäºçŸ¥è¯†åº“ç»“æœç”Ÿæˆå¢å¼ºå›ç­”"""
        try:
            # æ„å»ºä¸Šä¸‹æ–‡
            context = "\n\n".join([result["content"] for result in knowledge_results[:3]])
            
            prompt = PromptTemplate.from_template("""
åŸºäºä»¥ä¸‹çŸ¥è¯†åº“å†…å®¹å’Œå…¶ä»–ç›¸å…³ä¿¡æ¯ï¼Œå›ç­”é—®é¢˜ï¼š

çŸ¥è¯†åº“å†…å®¹ï¼š
{context}

å…¶ä»–ç›¸å…³ä¿¡æ¯ï¼š
{all_context}

é—®é¢˜ï¼š{question}

è¯·æ ¹æ®çŸ¥è¯†åº“å†…å®¹ç»™å‡ºå‡†ç¡®ã€è¯¦ç»†çš„å›ç­”ã€‚å¦‚æœå…¶ä»–ä¿¡æ¯ä¸é—®é¢˜ç›¸å…³ï¼Œè¯·ç»“åˆåˆ†æã€‚
å›ç­”è¦ç»“æ„æ¸…æ™°ï¼Œé‡ç‚¹çªå‡ºã€‚
""")
            
            response = self.llm.invoke(prompt.format(
                context=context, 
                all_context=all_context, 
                question=query
            ))
            return response.content
            
        except Exception as e:
            return f"âŒ åŸºäºçŸ¥è¯†åº“ç”Ÿæˆå›ç­”å¤±è´¥: {str(e)}"
    
    def _route_to_appropriate_agent(self, query: str, all_context: str) -> str:
        """æ™ºèƒ½è·¯ç”±åˆ°åˆé€‚çš„Agent"""
        try:
            # åˆ¤æ–­é—®é¢˜ç±»å‹
            if any(keyword in query for keyword in ["é”€å”®", "åº“å­˜", "ä¾›åº”", "åŒ—äº¬ä¸­å…³æ‘åº—", "é—¨åº—", "æ•°æ®"]):
                # æ•°æ®åº“æŸ¥è¯¢ + ç»“åˆçŸ¥è¯†åº“
                db_answer = self.database_agent.query(query, all_context)
                
                # å¦‚æœæ•°æ®åº“æœ‰ç»“æœï¼Œè¿›ä¸€æ­¥ç»“åˆPDFä¿¡æ¯
                if db_answer and "æœªæ‰¾åˆ°" not in db_answer:
                    enhanced_answer = self._enhance_with_pdf_context(db_answer, query)
                    return enhanced_answer
                else:
                    return db_answer
            else:
                # ä½¿ç”¨PDF Agents + ç»“åˆæ•°æ®åº“ä¿¡æ¯
                answers = []
                for agent_name, agent in self.pdf_agents.items():
                    try:
                        answer = agent.query(query, all_context)
                        if answer and "æœªæ‰¾åˆ°" not in answer:
                            answers.append(f"[{agent_name}]: {answer}")
                    except Exception as e:
                        print(f"âŒ PDF Agent {agent_name} æŸ¥è¯¢å¤±è´¥: {e}")
                
                if answers:
                    combined_answer = "\n\n".join(answers)
                    # è¿›ä¸€æ­¥ç»“åˆæ•°æ®åº“ä¿¡æ¯
                    enhanced_answer = self._enhance_with_db_context(combined_answer, query)
                    return enhanced_answer
                else:
                    return "âŒ åœ¨ç°æœ‰çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
                    
        except Exception as e:
            return f"âŒ Agentè·¯ç”±å¤±è´¥: {str(e)}"
    
    def _enhance_with_pdf_context(self, db_answer: str, query: str) -> str:
        """ç”¨PDFä¿¡æ¯å¢å¼ºæ•°æ®åº“å›ç­”"""
        try:
            pdf_contexts = []
            for agent_name, agent in self.pdf_agents.items():
                try:
                    pdf_result = agent.query(query, db_answer)
                    if pdf_result and "æœªæ‰¾åˆ°" not in pdf_result:
                        pdf_contexts.append(f"[{agent_name}è¡¥å……]: {pdf_result}")
                except:
                    pass
            
            if pdf_contexts:
                enhanced_answer = f"{db_answer}\n\nğŸ“š çŸ¥è¯†åº“è¡¥å……ä¿¡æ¯ï¼š\n" + "\n\n".join(pdf_contexts)
                return enhanced_answer
            else:
                return db_answer
                
        except Exception as e:
            return f"{db_answer}\n\nâŒ PDFå¢å¼ºå¤±è´¥: {str(e)}"
    
    def _enhance_with_db_context(self, pdf_answer: str, query: str) -> str:
        """ç”¨æ•°æ®åº“ä¿¡æ¯å¢å¼ºPDFå›ç­”"""
        try:
            # å°è¯•è·å–ç›¸å…³æ•°æ®åº“ä¿¡æ¯
            db_context = self.database_agent._query_general_data(query, pdf_answer)
            if db_context and "è¯·æä¾›æ›´å…·ä½“" not in db_context:
                enhanced_answer = f"{pdf_answer}\n\nğŸ’¾ æ•°æ®åº“è¡¥å……ä¿¡æ¯ï¼š\n{db_context}"
                return enhanced_answer
            else:
                return pdf_answer
                
        except Exception as e:
            return f"{pdf_answer}\n\nâŒ æ•°æ®åº“å¢å¼ºå¤±è´¥: {str(e)}"
    
    def _fallback_to_llm(self, query: str) -> str:
        """å›é€€åˆ°LLMç›´æ¥å›ç­”"""
        try:
            response = self.llm.invoke(f"è¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š{query}")
            return response.content
        except Exception as e:
            return f"âŒ LLMå›ç­”å¤±è´¥: {str(e)}"
    
    def close(self):
        """å…³é—­ç³»ç»Ÿ"""
        print("ğŸ”š Agentic RAGç³»ç»Ÿå·²å…³é—­")

def display_result(result: Dict):
    """æ ¼å¼åŒ–æ˜¾ç¤ºç»“æœ"""
    print("\n" + "="*50)
    print("ğŸ“ å›ç­”")
    print("="*50)
    print(result['answer'])
    
    print(f"\nğŸ¯ ç½®ä¿¡åº¦: {result.get('confidence', 0):.1%}")
    if result.get('relevance_score'):
        print(f"ğŸ“Š çŸ¥è¯†åº“åŒ¹é…åº¦: {result.get('relevance_score', 0):.1%}")
    
    print("\nğŸ“‹ ä¿¡æ¯æ¥æº")
    print("-" * 20)
    source_type = result.get('source_type', 'unknown')
    if source_type == "knowledge_base":
        print("âœ… çŸ¥è¯†åº“ç›´æ¥åŒ¹é…")
    elif source_type == "agent_system":
        print("ğŸ¤– å¤šAgentåè°ƒç³»ç»Ÿ")
    elif source_type == "llm_fallback":
        print("âš ï¸ LLMç›´æ¥ç”Ÿæˆ")
    elif source_type == "duplicate":
        print("ğŸ”„ é‡å¤æŸ¥è¯¢æ£€æµ‹")
    else:
        print("â“ æœªçŸ¥æ¥æº")

def main():
    print("ğŸš€ === æ™ºèƒ½Agentic RAGä»“åº“ç®¡ç†ç³»ç»Ÿ ===")
    print("ğŸ’¡ è¯·è¾“å…¥æ‚¨çš„æŸ¥è¯¢ï¼š")
    print("ğŸ”š è¾“å…¥'é€€å‡º'æˆ–'quit'ç»“æŸä¼šè¯\n")
    
    system = AgenticRAGSystem()
    
    try:
        while True:
            query = input("\nğŸ¤” è¯·è¾“å…¥æ‚¨çš„æŸ¥è¯¢> ").strip()
            if not query:
                continue
            if query.lower() in ['quit', 'exit', 'é€€å‡º']:
                break
            
            result = system.process_query(query)
            display_result(result)
          
    finally:
        system.close()
        print("\nğŸ‘‹ ç³»ç»Ÿå·²å…³é—­")

if __name__ == "__main__":
    try:
        from langchain_openai import ChatOpenAI
        from langchain_huggingface import HuggingFaceEmbeddings
        from langchain_community.vectorstores import FAISS
        from langchain.text_splitter import RecursiveCharacterTextSplitter
        from langchain.prompts import PromptTemplate
    except ImportError:
        print("âŒ è¯·å…ˆå®‰è£…ä¾èµ–: pip install langchain-openai langchain-huggingface langchain pymupdf sentence-transformers faiss-cpu python-dotenv")
        exit(1)
    
    main()
