'''
    é€šç”¨æ•°æ®åº“Agent - æ”¯æŒä»»ä½•PostgreSQLæ•°æ®åº“ç»“æ„
'''

import os
import json
import psycopg2
from typing import List, Dict, Tuple, Optional
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
import textwrap

from config import Config
from API_TextToText.API_of_RAG._8_DatabaseSchemaAnalyzer import DatabaseSchemaAnalyzer

class UniversalDatabaseAgent:
    """é€šç”¨æ•°æ®åº“Agent - æ”¯æŒä»»ä½•PostgreSQLæ•°æ®åº“ç»“æ„"""
    
    def __init__(self):
        self.llm = ChatOpenAI(
            model_name=Config.RAG_MODEL_NAME,
            openai_api_key=Config.RAG_OPENAI_API_KEY,
            openai_api_base=Config.RAG_OPENAI_API_URL,
            temperature=0.3
        )
        self.conn = psycopg2.connect(
            host=Config.DB_HOST, port=Config.DB_PORT, database=Config.DB_NAME, user=Config.DB_USER, password=Config.DB_PASSWORD
        )
        self.schema_analyzer = DatabaseSchemaAnalyzer(self.conn)
    
    def analyze_query_intent(self, question: str) -> Dict:
        """æ™ºèƒ½åˆ†æç”¨æˆ·æŸ¥è¯¢æ„å›¾ï¼Œå°†è‡ªç„¶è¯­è¨€è½¬æ¢ä¸ºæ•°æ®åº“æŸ¥è¯¢éœ€æ±‚"""
        try:
            print(f"ğŸ§  å¼€å§‹åˆ†ææŸ¥è¯¢æ„å›¾: {question}")
            
            # è·å–æ•°æ®åº“æ¨¡å¼ä¿¡æ¯
            schema_summary = self.schema_analyzer.get_schema_summary()
            
                                      # æ„å»ºæ„å›¾åˆ†ææç¤º
            intent_prompt = PromptTemplate.from_template("""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åº“æŸ¥è¯¢æ„å›¾åˆ†æä¸“å®¶ã€‚è¯·åˆ†æç”¨æˆ·çš„é—®é¢˜ï¼Œå°†å…¶è½¬æ¢ä¸ºå…·ä½“çš„æ•°æ®åº“æŸ¥è¯¢éœ€æ±‚ã€‚

æ•°æ®åº“æ¨¡å¼ä¿¡æ¯ï¼š
{schema_summary}

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·åˆ†æç”¨æˆ·æ„å›¾å¹¶è¿”å›JSONæ ¼å¼çš„æŸ¥è¯¢éœ€æ±‚ï¼š
{{
    "query_type": "é”€å”®åˆ†æ/åº“å­˜åˆ†æ/äº§å“åˆ†æ/ä»“åº“åˆ†æ/é—¨åº—åˆ†æ/è¡¥è´§åˆ†æ/è¶‹åŠ¿åˆ†æ/ç»¼åˆæŸ¥è¯¢",
    "target_tables": ["è¡¨å1", "è¡¨å2"],
    "target_columns": ["å­—æ®µ1", "å­—æ®µ2"],
    "filter_conditions": {{
        "category": "äº§å“ç±»åˆ«ï¼ˆå¦‚ï¼šELECTRONICS, BEVERAGE, SNACKç­‰ï¼‰",
        "location": "ä½ç½®ä¿¡æ¯ï¼ˆå¦‚ï¼šä»“åº“IDã€é—¨åº—IDï¼‰",
        "time_range": "æ—¶é—´èŒƒå›´",
        "product_name": "äº§å“åç§°å…³é”®è¯",
        "warehouse_name": "ä»“åº“åç§°å…³é”®è¯",
        "store_name": "é—¨åº—åç§°å…³é”®è¯"
    }},
    "aggregation": {{
        "functions": ["SUM", "COUNT", "AVG", "MAX", "MIN"],
        "group_by": ["åˆ†ç»„å­—æ®µ"],
        "order_by": ["æ’åºå­—æ®µ"]
    }},
    "business_insight": "ä¸šåŠ¡æ´å¯Ÿéœ€æ±‚",
    "confidence": 0.0-1.0
}}

æ™ºèƒ½è¯†åˆ«è§„åˆ™ï¼š

1. äº§å“ç±»åˆ«æ˜ å°„ï¼ˆå¿…é¡»å‡†ç¡®è¯†åˆ«ï¼Œä¸”categoryå€¼å¿…é¡»ä¸æ•°æ®åº“å­—æ®µå®Œå…¨ä¸€è‡´ï¼ŒåŒºåˆ†å¤§å°å†™ã€‚ä¾‹å¦‚ï¼šELECTRONICSã€BEVERAGEã€SNACKã€DAILYã€FROZENã€APPLIANCEç­‰ï¼‰ï¼š
   - "ç”µå­äº§å“"ã€"ç”µå­"ã€"æ•°ç "ã€"æ‰‹æœº"ã€"ç”µè„‘"ã€"è€³æœº"ã€"å……ç”µå®"ã€"iPhone"ã€"åä¸º"ã€"å°ç±³" â†’ category: "ELECTRONICS"
   - "é¥®æ–™"ã€"çŸ¿æ³‰æ°´"ã€"å¯ä¹"ã€"ç‰›å¥¶"ã€"èŒ¶"ã€"å’–å•¡"ã€"çº¢ç‰›"ã€"ä¼Šåˆ©" â†’ category: "BEVERAGE" 
   - "é›¶é£Ÿ"ã€"è–¯ç‰‡"ã€"å·§å…‹åŠ›"ã€"é¥¼å¹²"ã€"åšæœ"ã€"ç³–æœ"ã€"ä¹äº‹"ã€"å¾·èŠ™"ã€"å¥¥åˆ©å¥¥" â†’ category: "SNACK"
   - "æ—¥ç”¨å“"ã€"æ´—å‘æ°´"ã€"ç‰™è†"ã€"é¦™çš‚"ã€"çº¸å·¾"ã€"æ´—è¡£æ¶²"ã€"æµ·é£ä¸"ã€"ä½³æ´å£«"ã€"èˆ’è‚¤ä½³" â†’ category: "DAILY"
   - "å†·å†»é£Ÿå“"ã€"å†°æ·‡æ·‹"ã€"æ°´é¥º"ã€"ç‰›æ’"ã€"æ±¤åœ†"ã€"é€Ÿå†»"ã€"æ¹¾ä»”ç å¤´"ã€"å“ˆæ ¹è¾¾æ–¯" â†’ category: "FROZEN"
   - "å®¶ç”µ"ã€"ç©ºè°ƒ"ã€"å†°ç®±"ã€"å¸å°˜å™¨"ã€"ç”µè§†"ã€"æ´—è¡£æœº"ã€"æˆ´æ£®"ã€"ç¾çš„"ã€"æ ¼åŠ›"ã€"ç´¢å°¼" â†’ category: "APPLIANCE"
   
   âš ï¸ æ³¨æ„ï¼šcategoryå­—æ®µçš„å€¼å¿…é¡»ä¸æ•°æ®åº“å®é™…å­—æ®µå€¼å®Œå…¨ä¸€è‡´ï¼ŒåŒºåˆ†å¤§å°å†™ï¼ˆå¦‚ELECTRONICSã€BEVERAGEç­‰ï¼‰ï¼Œä¸è¦è¾“å‡ºå°å†™æˆ–å…¶ä»–å˜ä½“ã€‚

2. æŸ¥è¯¢ç±»å‹è¯†åˆ«ï¼š
   - åŒ…å«"é”€å”®"ã€"é”€é‡"ã€"é”€å”®é¢"ã€"å–"ã€"å”®å‡º" â†’ query_type: "é”€å”®åˆ†æ"
   - åŒ…å«"åº“å­˜"ã€"å­˜è´§"ã€"åº“å­˜é‡"ã€"åº“å­˜æƒ…å†µ"ã€"åº“å­˜çŠ¶æ€" â†’ query_type: "åº“å­˜åˆ†æ"
   - åŒ…å«"äº§å“"ã€"å•†å“"ã€"SKU"ã€"äº§å“ä¿¡æ¯"ã€"äº§å“è¯¦æƒ…"ã€"æŸ¥è¯¢"ã€"æŸ¥çœ‹" â†’ query_type: "äº§å“åˆ†æ"
   - åŒ…å«"ä»“åº“"ã€"ä»“"ã€"ä¸­å¿ƒä»“"ã€"ä»“åº“ä¿¡æ¯" â†’ query_type: "ä»“åº“åˆ†æ"
   - åŒ…å«"é—¨åº—"ã€"åº—é“º"ã€"åº—"ã€"é—¨åº—ä¿¡æ¯"ã€"é—¨åº—æƒ…å†µ" â†’ query_type: "é—¨åº—åˆ†æ"
   - åŒ…å«"è¡¥è´§"ã€"è¿›è´§"ã€"é‡‡è´­"ã€"è¡¥è´§æƒ…å†µ" â†’ query_type: "è¡¥è´§åˆ†æ"
   - åŒ…å«"è¶‹åŠ¿"ã€"å˜åŒ–"ã€"å¢é•¿"ã€"è¶‹åŠ¿åˆ†æ" â†’ query_type: "è¶‹åŠ¿åˆ†æ"

3. æ’åºå’Œèšåˆè¯†åˆ«ï¼š
   - åŒ…å«"ä»·æ ¼æœ€é«˜"ã€"æœ€è´µ"ã€"æœ€é«˜ä»·" â†’ order_by: ["unit_price DESC"]
   - åŒ…å«"ä»·æ ¼æœ€ä½"ã€"æœ€ä¾¿å®œ"ã€"æœ€ä½ä»·" â†’ order_by: ["unit_price ASC"]
   - åŒ…å«"é”€é‡æœ€é«˜"ã€"æœ€ç•…é”€"ã€"å–å¾—æœ€å¥½" â†’ order_by: ["total_sales_quantity DESC"]
   - åŒ…å«"é”€å”®é¢æœ€é«˜"ã€"æ”¶å…¥æœ€é«˜"ã€"è¥ä¸šé¢æœ€é«˜" â†’ order_by: ["total_sales_amount DESC"]
   - åŒ…å«"åº“å­˜æœ€å¤š"ã€"åº“å­˜é‡æœ€å¤§" â†’ order_by: ["total_warehouse_stock DESC"]
   - åŒ…å«"åº“å­˜æœ€å°‘"ã€"åº“å­˜ä¸è¶³" â†’ order_by: ["total_warehouse_stock ASC"]

4. ä½ç½®è¯†åˆ«ï¼š
   - åŒ…å«"åŒ—äº¬"ã€"ä¸Šæµ·"ã€"å¹¿å·"ã€"æ·±åœ³"ç­‰åŸå¸‚å â†’ æŸ¥æ‰¾å¯¹åº”çš„é—¨åº—æˆ–ä»“åº“
   - åŒ…å«"ç‹åºœäº•"ã€"å¾å®¶æ±‡"ã€"å¤©æ²³åŸ"ç­‰å…·ä½“åœ°ç‚¹ â†’ æŸ¥æ‰¾å¯¹åº”çš„é—¨åº—
   - åŒ…å«"ååŒ—"ã€"åä¸œ"ã€"åå—"ã€"è¥¿å—"ç­‰åŒºåŸŸ â†’ æŸ¥æ‰¾å¯¹åº”çš„ä»“åº“

5. æ—¶é—´è¯†åˆ«ï¼š
   - åŒ…å«"ä»Šå¤©"ã€"æ˜¨å¤©"ã€"æœ¬å‘¨"ã€"æœ¬æœˆ"ã€"æœ€è¿‘" â†’ è®¾ç½®ç›¸åº”çš„æ—¶é—´èŒƒå›´
   - åŒ…å«"7å¤©"ã€"30å¤©"ã€"ä¸€å‘¨"ã€"ä¸€ä¸ªæœˆ" â†’ è®¾ç½®å…·ä½“çš„æ—¶é—´é—´éš”

6. è¡¨å…³è”è§„åˆ™ï¼š
   - é”€å”®åˆ†æï¼šsales + product + store + warehouse
   - åº“å­˜åˆ†æï¼šwarehouse_inventory + store_inventory + product + warehouse
   - äº§å“åˆ†æï¼šproduct + sales + warehouse_inventory + store_inventory
   - ä»“åº“åˆ†æï¼šwarehouse + warehouse_inventory + replenishment + store
   - é—¨åº—åˆ†æï¼šstore + sales + store_inventory + warehouse
   - è¡¥è´§åˆ†æï¼šreplenishment + warehouse + store + product

7. å­—æ®µæ˜ å°„ï¼š
   - é”€å”®ç›¸å…³ï¼šquantity(æ•°é‡), total_amount(é‡‘é¢), sale_date(é”€å”®æ—¥æœŸ)
   - åº“å­˜ç›¸å…³ï¼šquantity(ä»“åº“åº“å­˜), stock_quantity(é—¨åº—åº“å­˜), safety_stock(å®‰å…¨åº“å­˜)
   - äº§å“ç›¸å…³ï¼šproduct_name(äº§å“å), category(ç±»åˆ«), unit_price(å•ä»·), cost_price(æˆæœ¬ä»·)
   - ä½ç½®ç›¸å…³ï¼šwarehouse_name(ä»“åº“å), store_name(é—¨åº—å), address(åœ°å€)

8. ä¸šåŠ¡æ´å¯Ÿè¯†åˆ«ï¼š
   - "ä»·æ ¼æœ€é«˜" â†’ business_insight: "æŸ¥æ‰¾ä»·æ ¼æœ€é«˜çš„äº§å“ï¼Œä¾¿äºäº†è§£é«˜ç«¯å•†å“å®šä»·"
   - "é”€é‡æœ€å¥½" â†’ business_insight: "åˆ†ææœ€ç•…é”€äº§å“ï¼Œäº†è§£å¸‚åœºéœ€æ±‚"
   - "åº“å­˜ä¸è¶³" â†’ business_insight: "è¯†åˆ«åº“å­˜ä¸è¶³çš„äº§å“ï¼Œéœ€è¦è¡¥è´§"
   - "é”€å”®è¶‹åŠ¿" â†’ business_insight: "åˆ†æäº§å“é”€å”®è¶‹åŠ¿ï¼Œé¢„æµ‹æœªæ¥éœ€æ±‚"

è¯·ä»”ç»†åˆ†æç”¨æˆ·é—®é¢˜ï¼Œå‡†ç¡®è¯†åˆ«æŸ¥è¯¢æ„å›¾ï¼Œç¡®ä¿è¿”å›çš„JSONæ ¼å¼æ­£ç¡®ã€‚
åªè¿”å›JSONæ ¼å¼ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚
""")
            
            response = self.llm.invoke(intent_prompt.format(
                schema_summary=schema_summary,
                question=question
            ))
            
            # è§£æJSONå“åº”
            intent_data = json.loads(response.content.strip())
            print(f"âœ… æŸ¥è¯¢æ„å›¾åˆ†æå®Œæˆ: {intent_data}")
            
            return intent_data
            
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢æ„å›¾åˆ†æå¤±è´¥: {e}")
            # è¿”å›é»˜è®¤æ„å›¾
            return {
                "query_type": "ç»¼åˆæŸ¥è¯¢",
                "target_tables": [],
                "target_columns": [],
                "filter_conditions": {},
                "aggregation": {
                    "functions": [],
                    "group_by": [],
                    "order_by": []
                },
                "business_insight": "é€šç”¨æŸ¥è¯¢",
                "confidence": 0.5
            }
    
    def generate_sql_from_intent(self, intent: Dict) -> Optional[str]:
        """åŸºäºæŸ¥è¯¢æ„å›¾ç”ŸæˆSQL"""
        try:
            print(f"ğŸ”§ åŸºäºæ„å›¾ç”ŸæˆSQL: {intent}")
            
            # å¢å¼ºæ„å›¾åˆ†æï¼Œæ·»åŠ ä½ç½®ä¿¡æ¯
            enhanced_intent = self._enhance_intent_with_location(intent)
            print(f"ğŸ”§ å¢å¼ºåçš„æ„å›¾: {enhanced_intent}")
            
            query_type = enhanced_intent.get("query_type", "ç»¼åˆæŸ¥è¯¢")
            target_tables = enhanced_intent.get("target_tables", [])
            filter_conditions = enhanced_intent.get("filter_conditions", {})
            aggregation = enhanced_intent.get("aggregation", {})
            
            # æ ¹æ®æŸ¥è¯¢ç±»å‹ç”Ÿæˆä¸åŒçš„SQL
            if query_type == "é”€å”®åˆ†æ":
                sql = self._generate_sales_sql(enhanced_intent)
            elif query_type == "åº“å­˜åˆ†æ":
                sql = self._generate_inventory_sql(enhanced_intent)
            elif query_type == "äº§å“åˆ†æ":
                sql = self._generate_product_sql(enhanced_intent)
            elif query_type == "ä»“åº“åˆ†æ":
                sql = self._generate_warehouse_sql(enhanced_intent)
            elif query_type == "é—¨åº—åˆ†æ":
                sql = self._generate_store_sql(enhanced_intent)
            elif query_type == "è¡¥è´§åˆ†æ":
                sql = self._generate_replenishment_sql(enhanced_intent)
            elif query_type == "è¶‹åŠ¿åˆ†æ":
                sql = self._generate_trend_sql(enhanced_intent)
            else:
                sql = self._generate_general_sql(enhanced_intent)
            
            print(f"âœ… ç”Ÿæˆçš„SQL: {sql}")
            return sql
            
        except Exception as e:
            print(f"âŒ SQLç”Ÿæˆå¤±è´¥: {e}")
            return None
    
    def _generate_sales_sql(self, intent: Dict) -> str:
        """ç”Ÿæˆé”€å”®åˆ†æSQL"""
        filter_conditions = intent.get("filter_conditions", {})
        
        sql = """
        SELECT 
            p.product_name,
            p.category,
            st.store_name,
            w.warehouse_name,
            s.sale_date,
            s.quantity,
            s.unit_price,
            s.total_amount
        FROM sales s
        JOIN product p ON s.product_id = p.product_id
        JOIN store st ON s.store_id = st.store_id
        LEFT JOIN warehouse w ON st.warehouse_id = w.warehouse_id
        WHERE 1=1
        """
        
        # æ·»åŠ è¿‡æ»¤æ¡ä»¶
        if filter_conditions.get("category"):
            sql += f" AND p.category = '{filter_conditions['category']}'"
        
        if filter_conditions.get("location"):
            sql += f" AND (st.store_id = '{filter_conditions['location']}' OR w.warehouse_id = '{filter_conditions['location']}')"
        
        if filter_conditions.get("product_name"):
            sql += f" AND p.product_name LIKE '%{filter_conditions['product_name']}%'"
        
        if filter_conditions.get("store_name"):
            sql += f" AND st.store_name LIKE '%{filter_conditions['store_name']}%'"
        
        sql += " ORDER BY s.sale_date DESC LIMIT 20"
        
        return sql
    
    def _generate_inventory_sql(self, intent: Dict) -> str:
        """ç”Ÿæˆåº“å­˜åˆ†æSQL"""
        filter_conditions = intent.get("filter_conditions", {})
        
        sql = """
        SELECT 
            p.product_name,
            p.category,
            w.warehouse_name,
            wi.quantity as warehouse_quantity,
            si.stock_quantity as store_quantity,
            si.safety_stock,
            wi.record_date
        FROM warehouse_inventory wi
        JOIN product p ON wi.product_id = p.product_id
        JOIN warehouse w ON wi.warehouse_id = w.warehouse_id
        LEFT JOIN store_inventory si ON wi.product_id = si.product_id
        WHERE 1=1
        """
        
        # æ·»åŠ è¿‡æ»¤æ¡ä»¶
        if filter_conditions.get("category"):
            sql += f" AND p.category = '{filter_conditions['category']}'"
        
        if filter_conditions.get("location"):
            sql += f" AND (w.warehouse_id = '{filter_conditions['location']}' OR si.store_id = '{filter_conditions['location']}')"
        
        if filter_conditions.get("product_name"):
            sql += f" AND p.product_name LIKE '%{filter_conditions['product_name']}%'"
        
        if filter_conditions.get("warehouse_name"):
            sql += f" AND w.warehouse_name LIKE '%{filter_conditions['warehouse_name']}%'"
        
        sql += " ORDER BY wi.record_date DESC LIMIT 20"
        
        return sql
    
    def _generate_product_sql(self, intent: Dict) -> str:
        """ç”Ÿæˆäº§å“åˆ†æSQL"""
        filter_conditions = intent.get("filter_conditions", {})
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æŒ‰ä»·æ ¼æ’åº
        aggregation = intent.get("aggregation", {})
        order_by = aggregation.get("order_by", [])
        
        # åŸºç¡€SQL
        sql = """
        SELECT 
            p.product_id,
            p.product_name,
            p.category,
            p.unit_price,
            p.cost_price,
            p.barcode,
            COALESCE(SUM(s.quantity), 0) as total_sales_quantity,
            COALESCE(SUM(s.total_amount), 0) as total_sales_amount,
            COALESCE(SUM(wi.quantity), 0) as total_warehouse_stock,
            COALESCE(SUM(si.stock_quantity), 0) as total_store_stock
        FROM product p
        LEFT JOIN sales s ON p.product_id = s.product_id
        LEFT JOIN warehouse_inventory wi ON p.product_id = wi.product_id
        LEFT JOIN store_inventory si ON p.product_id = si.product_id
        WHERE 1=1
        """
        
        # æ·»åŠ è¿‡æ»¤æ¡ä»¶
        if filter_conditions.get("category"):
            sql += f" AND p.category = '{filter_conditions['category']}'"
        
        if filter_conditions.get("product_name"):
            sql += f" AND p.product_name LIKE '%{filter_conditions['product_name']}%'"
        
        sql += " GROUP BY p.product_id, p.product_name, p.category, p.unit_price, p.cost_price, p.barcode"
        
        # æ ¹æ®æ„å›¾é€‰æ‹©æ’åºæ–¹å¼
        if "ä»·æ ¼æœ€é«˜" in intent.get("business_insight", "") or "unit_price DESC" in order_by:
            sql += " ORDER BY p.unit_price DESC"
        elif "ä»·æ ¼æœ€ä½" in intent.get("business_insight", "") or "unit_price ASC" in order_by:
            sql += " ORDER BY p.unit_price ASC"
        elif "é”€é‡æœ€é«˜" in intent.get("business_insight", "") or "total_sales_quantity DESC" in order_by:
            sql += " ORDER BY total_sales_quantity DESC"
        elif "é”€å”®é¢æœ€é«˜" in intent.get("business_insight", "") or "total_sales_amount DESC" in order_by:
            sql += " ORDER BY total_sales_amount DESC"
        else:
            sql += " ORDER BY p.product_name"
        
        sql += " LIMIT 20"
        
        return textwrap.dedent(sql)
    
    def _generate_warehouse_sql(self, intent: Dict) -> str:
        """ç”Ÿæˆä»“åº“åˆ†æSQL"""
        filter_conditions = intent.get("filter_conditions", {})
        
        sql = """
        SELECT 
            w.warehouse_id,
            w.warehouse_name,
            w.address,
            w.created_at,
            COUNT(DISTINCT wi.product_id) as product_count,
            SUM(wi.quantity) as total_inventory,
            COUNT(DISTINCT r.replenishment_id) as replenishment_count,
            COUNT(DISTINCT st.store_id) as store_count
        FROM warehouse w
        LEFT JOIN warehouse_inventory wi ON w.warehouse_id = wi.warehouse_id
        LEFT JOIN replenishment r ON w.warehouse_id = r.warehouse_id
        LEFT JOIN store st ON w.warehouse_id = st.warehouse_id
        WHERE 1=1
        """
        
        # æ·»åŠ è¿‡æ»¤æ¡ä»¶
        if filter_conditions.get("location"):
            sql += f" AND w.warehouse_id = '{filter_conditions['location']}'"
        
        if filter_conditions.get("warehouse_name"):
            sql += f" AND w.warehouse_name LIKE '%{filter_conditions['warehouse_name']}%'"
        
        sql += " GROUP BY w.warehouse_id, w.warehouse_name, w.address, w.created_at"
        sql += " ORDER BY total_inventory DESC LIMIT 20"
        
        return textwrap.dedent(sql)
    
    def _generate_store_sql(self, intent: Dict) -> str:
        """ç”Ÿæˆé—¨åº—åˆ†æSQL"""
        filter_conditions = intent.get("filter_conditions", {})
        
        sql = """
        SELECT 
            st.store_id,
            st.store_name,
            st.address,
            st.opened_date,
            w.warehouse_name,
            COUNT(DISTINCT s.sales_id) as sales_count,
            SUM(s.quantity) as total_sales_quantity,
            SUM(s.total_amount) as total_sales_amount,
            COUNT(DISTINCT si.product_id) as product_count,
            SUM(si.stock_quantity) as total_stock
        FROM store st
        LEFT JOIN warehouse w ON st.warehouse_id = w.warehouse_id
        LEFT JOIN sales s ON st.store_id = s.store_id
        LEFT JOIN store_inventory si ON st.store_id = si.store_id
        WHERE 1=1
        """
        
        # æ·»åŠ è¿‡æ»¤æ¡ä»¶
        if filter_conditions.get("location"):
            sql += f" AND st.store_id = '{filter_conditions['location']}'"
        
        if filter_conditions.get("store_name"):
            sql += f" AND st.store_name LIKE '%{filter_conditions['store_name']}%'"
        
        sql += " GROUP BY st.store_id, st.store_name, st.address, st.opened_date, w.warehouse_name"
        sql += " ORDER BY total_sales_amount DESC LIMIT 20"
        
        return textwrap.dedent(sql)
    
    def _generate_replenishment_sql(self, intent: Dict) -> str:
        """ç”Ÿæˆè¡¥è´§åˆ†æSQL"""
        filter_conditions = intent.get("filter_conditions", {})
        
        sql = """
        SELECT 
            r.replenishment_id,
            w.warehouse_name,
            st.store_name,
            p.product_name,
            p.category,
            r.shipment_date,
            r.shipped_quantity,
            r.received_quantity,
            r.status,
            (r.shipped_quantity - COALESCE(r.received_quantity, 0)) as pending_quantity
        FROM replenishment r
        JOIN warehouse w ON r.warehouse_id = w.warehouse_id
        JOIN store st ON r.store_id = st.store_id
        JOIN product p ON r.product_id = p.product_id
        WHERE 1=1
        """
        
        # æ·»åŠ è¿‡æ»¤æ¡ä»¶
        if filter_conditions.get("location"):
            sql += f" AND (r.warehouse_id = '{filter_conditions['location']}' OR r.store_id = '{filter_conditions['location']}')"
        
        if filter_conditions.get("category"):
            sql += f" AND p.category = '{filter_conditions['category']}'"
        
        sql += " ORDER BY r.shipment_date DESC LIMIT 20"
        
        return textwrap.dedent(sql)
    
    def _generate_trend_sql(self, intent: Dict) -> str:
        """ç”Ÿæˆè¶‹åŠ¿åˆ†æSQL"""
        filter_conditions = intent.get("filter_conditions", {})
        
        sql = """
        SELECT 
            DATE_TRUNC('day', s.sale_date) as sale_day,
            p.category,
            SUM(s.quantity) as daily_sales_quantity,
            SUM(s.total_amount) as daily_sales_amount,
            COUNT(DISTINCT s.sales_id) as daily_order_count
        FROM sales s
        JOIN product p ON s.product_id = p.product_id
        WHERE 1=1
        """
        
        # æ·»åŠ è¿‡æ»¤æ¡ä»¶
        if filter_conditions.get("category"):
            sql += f" AND p.category = '{filter_conditions['category']}'"
        
        if filter_conditions.get("time_range"):
            sql += f" AND s.sale_date >= CURRENT_DATE - INTERVAL '{filter_conditions['time_range']}'"
        
        sql += " GROUP BY DATE_TRUNC('day', s.sale_date), p.category"
        sql += " ORDER BY sale_day DESC, daily_sales_amount DESC LIMIT 20"
        
        return textwrap.dedent(sql)
    
    def _generate_general_sql(self, intent: Dict) -> str:
        """ç”Ÿæˆé€šç”¨æŸ¥è¯¢SQL"""
        # é»˜è®¤æŸ¥è¯¢æ‰€æœ‰è¡¨çš„åŸºæœ¬ä¿¡æ¯
        sql = """
        SELECT 
            'product' as table_name,
            COUNT(*) as record_count,
            'äº§å“ä¿¡æ¯è¡¨' as description
        FROM product
        UNION ALL
        SELECT 
            'sales' as table_name,
            COUNT(*) as record_count,
            'é”€å”®è®°å½•è¡¨' as description
        FROM sales
        UNION ALL
        SELECT 
            'warehouse' as table_name,
            COUNT(*) as record_count,
            'ä»“åº“ä¿¡æ¯è¡¨' as description
        FROM warehouse
        UNION ALL
        SELECT 
            'store' as table_name,
            COUNT(*) as record_count,
            'é—¨åº—ä¿¡æ¯è¡¨' as description
        FROM store
        ORDER BY record_count DESC
        """
        
        return sql
    
    def _map_location_name(self, location_name: str) -> Dict:
        """æ™ºèƒ½æ˜ å°„ä½ç½®åç§°åˆ°æ•°æ®åº“ID"""
        try:
            # åŸå¸‚åˆ°é—¨åº—/ä»“åº“çš„æ˜ å°„
            city_mapping = {
                "åŒ—äº¬": {"stores": ["ST101"], "warehouses": ["WH001"]},
                "ä¸Šæµ·": {"stores": ["ST102"], "warehouses": ["WH002"]},
                "å¹¿å·": {"stores": ["ST103"], "warehouses": ["WH003"]},
                "æ·±åœ³": {"stores": ["ST104"], "warehouses": ["WH003"]},
                "æˆéƒ½": {"stores": ["ST105"], "warehouses": ["WH004"]},
                "é‡åº†": {"stores": ["ST106"], "warehouses": ["WH004"]},
                "æ­¦æ±‰": {"stores": ["ST107"], "warehouses": ["WH004"]},
                "å—äº¬": {"stores": ["ST108"], "warehouses": ["WH002"]},
                "æ­å·": {"stores": ["ST109"], "warehouses": ["WH002"]},
                "è¥¿å®‰": {"stores": ["ST110"], "warehouses": ["WH001"]}
            }
            
            # å…·ä½“åœ°ç‚¹åˆ°é—¨åº—çš„æ˜ å°„
            place_mapping = {
                "ç‹åºœäº•": "ST101",
                "å¾å®¶æ±‡": "ST102", 
                "å¤©æ²³åŸ": "ST103",
                "ä¸‡è±¡åŸ": "ST104",
                "æ˜¥ç†™è·¯": "ST105",
                "è§£æ”¾ç¢‘": "ST106",
                "æ­¦å•†å¹¿åœº": "ST107",
                "æ–°è¡—å£": "ST108",
                "è¥¿æ¹–": "ST109",
                "é’Ÿæ¥¼": "ST110"
            }
            
            # åŒºåŸŸåˆ°ä»“åº“çš„æ˜ å°„
            region_mapping = {
                "ååŒ—": "WH001",
                "åä¸œ": "WH002",
                "åå—": "WH003", 
                "è¥¿å—": "WH004",
                "ä¸œåŒ—": "WH005"
            }
            
            # æ£€æŸ¥åŸå¸‚æ˜ å°„
            for city, mapping in city_mapping.items():
                if city in location_name:
                    return mapping
            
            # æ£€æŸ¥å…·ä½“åœ°ç‚¹æ˜ å°„
            for place, store_id in place_mapping.items():
                if place in location_name:
                    return {"stores": [store_id], "warehouses": []}
            
            # æ£€æŸ¥åŒºåŸŸæ˜ å°„
            for region, warehouse_id in region_mapping.items():
                if region in location_name:
                    return {"stores": [], "warehouses": [warehouse_id]}
            
            return {"stores": [], "warehouses": []}
            
        except Exception as e:
            print(f"âš ï¸ ä½ç½®æ˜ å°„å¤±è´¥: {e}")
            return {"stores": [], "warehouses": []}
    
    def _enhance_intent_with_location(self, intent: Dict) -> Dict:
        """å¢å¼ºæ„å›¾åˆ†æï¼Œæ·»åŠ ä½ç½®ä¿¡æ¯"""
        try:
            filter_conditions = intent.get("filter_conditions", {})
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ä½ç½®ç›¸å…³çš„è¿‡æ»¤æ¡ä»¶
            if filter_conditions.get("location"):
                location_name = filter_conditions["location"]
                location_mapping = self._map_location_name(location_name)
                
                # æ ¹æ®æŸ¥è¯¢ç±»å‹é€‰æ‹©åˆé€‚çš„ID
                query_type = intent.get("query_type", "")
                
                if query_type in ["é—¨åº—åˆ†æ", "é”€å”®åˆ†æ"] and location_mapping["stores"]:
                    filter_conditions["location"] = location_mapping["stores"][0]
                elif query_type in ["ä»“åº“åˆ†æ", "åº“å­˜åˆ†æ"] and location_mapping["warehouses"]:
                    filter_conditions["location"] = location_mapping["warehouses"][0]
                elif location_mapping["stores"]:
                    filter_conditions["location"] = location_mapping["stores"][0]
                elif location_mapping["warehouses"]:
                    filter_conditions["location"] = location_mapping["warehouses"][0]
            
            intent["filter_conditions"] = filter_conditions
            return intent
            
        except Exception as e:
            print(f"âš ï¸ æ„å›¾ä½ç½®å¢å¼ºå¤±è´¥: {e}")
            return intent

    def generate_sql(self, question: str) -> Optional[str]:
        """ä½¿ç”¨LLMç”ŸæˆSQLæŸ¥è¯¢"""
        try:
            # 1. é¦–å…ˆè¿›è¡ŒæŸ¥è¯¢æ„å›¾åˆ†æ
            intent = self.analyze_query_intent(question)
            
            # 2. åŸºäºæ„å›¾ç”ŸæˆSQL
            sql = self.generate_sql_from_intent(intent)
            
            if sql and sql.upper().startswith('SELECT'):
                return sql
            return None
            
        except Exception as e:
            print(f"âŒ SQLç”Ÿæˆå¤±è´¥: {e}")
            return None
    
    def execute_query(self, sql: str) -> List[Tuple]:
        try:
            print(f"ğŸš€ æ‰§è¡ŒSQLæŸ¥è¯¢: {repr(sql)}")
            print(f"SQLç±»å‹: {type(sql)}")
            assert self.conn and self.conn.closed == 0, "æ•°æ®åº“è¿æ¥å·²å…³é—­"
            cursor = self.conn.cursor()
            cursor.execute(sql)
            rows = cursor.fetchall()
            cursor.close()
            print(f"âœ… æŸ¥è¯¢æ‰§è¡ŒæˆåŠŸï¼Œè¿”å› {len(rows)} è¡Œæ•°æ®")
            return rows
        except Exception as e:
            print(f"âŒ SQLæ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            # å†™å…¥æ—¥å¿—
            with open("sql_error.log", "a", encoding="utf-8") as f:
                f.write(f"SQLæ‰§è¡Œå¤±è´¥: {repr(sql)}\né”™è¯¯: {e}\n")
            return []
    
    def get_column_names(self, sql: str) -> List[str]:
        """è·å–æŸ¥è¯¢ç»“æœçš„åˆ—å"""
        try:
            cursor = self.conn.cursor()
            cursor.execute(sql)
            column_names = [desc[0] for desc in cursor.description]
            cursor.close()
            return column_names
        except Exception as e:
            print(f"âŒ è·å–åˆ—åå¤±è´¥: {e}")
            return []
    
    def analyze_data_statistics(self, rows: List[Tuple], column_names: List[str]) -> Dict:
        """åˆ†ææ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
        if not rows or not column_names:
            return {}
        
        stats = {}
        try:
            # è½¬æ¢ä¸ºDataFrameæ ¼å¼è¿›è¡Œåˆ†æ
            data_dict = {}
            for i, col_name in enumerate(column_names):
                data_dict[col_name] = [row[i] for row in rows]
            
            # æ•°å€¼å‹åˆ—ç»Ÿè®¡
            numeric_stats = {}
            for col_name, values in data_dict.items():
                try:
                    # å°è¯•è½¬æ¢ä¸ºæ•°å€¼
                    numeric_values = []
                    for val in values:
                        if val is not None:
                            try:
                                numeric_values.append(float(val))
                            except (ValueError, TypeError):
                                continue
                    
                    if numeric_values:
                        numeric_stats[col_name] = {
                            'count': len(numeric_values),
                            'min': min(numeric_values),
                            'max': max(numeric_values),
                            'avg': sum(numeric_values) / len(numeric_values),
                            'sum': sum(numeric_values)
                        }
                except Exception:
                    continue
            
            # åˆ†ç±»åˆ—ç»Ÿè®¡
            categorical_stats = {}
            for col_name, values in data_dict.items():
                if col_name not in numeric_stats:
                    try:
                        value_counts = {}
                        for val in values:
                            if val is not None:
                                val_str = str(val)
                                value_counts[val_str] = value_counts.get(val_str, 0) + 1
                        
                        if value_counts:
                            categorical_stats[col_name] = {
                                'unique_count': len(value_counts),
                                'top_values': sorted(value_counts.items(), key=lambda x: x[1], reverse=True)[:5]
                            }
                    except Exception:
                        continue
            
            stats = {
                'total_rows': len(rows),
                'numeric_columns': numeric_stats,
                'categorical_columns': categorical_stats
            }
            
        except Exception as e:
            print(f"âš ï¸ æ•°æ®ç»Ÿè®¡åˆ†æå¤±è´¥: {e}")
        
        return stats
    
    def analyze_data_trends(self, rows: List[Tuple], column_names: List[str]) -> Dict:
        """åˆ†ææ•°æ®è¶‹åŠ¿"""
        if not rows or not column_names:
            return {}
        
        trends = {}
        try:
            # æŸ¥æ‰¾æ—¶é—´ç›¸å…³åˆ—
            time_columns = []
            for col_name in column_names:
                if any(keyword in col_name.lower() for keyword in ['time', 'date', 'created', 'updated', 'timestamp']):
                    time_columns.append(col_name)
            
            if time_columns:
                # åˆ†ææ—¶é—´è¶‹åŠ¿
                for time_col in time_columns:
                    try:
                        time_idx = column_names.index(time_col)
                        time_values = [row[time_idx] for row in rows if row[time_idx] is not None]
                        
                        if time_values:
                            # ç®€å•çš„æ—¶é—´è¶‹åŠ¿åˆ†æ
                            trends[time_col] = {
                                'earliest': min(time_values),
                                'latest': max(time_values),
                                'total_periods': len(time_values)
                            }
                    except Exception:
                        continue
            
            # åˆ†ææ•°å€¼è¶‹åŠ¿
            data_dict = {}
            for i, col_name in enumerate(column_names):
                data_dict[col_name] = [row[i] for row in rows]
            
            for col_name, values in data_dict.items():
                try:
                    numeric_values = []
                    for val in values:
                        if val is not None:
                            try:
                                numeric_values.append(float(val))
                            except (ValueError, TypeError):
                                continue
                    
                    if len(numeric_values) > 1:
                        # è®¡ç®—è¶‹åŠ¿ï¼ˆç®€å•çº¿æ€§è¶‹åŠ¿ï¼‰
                        sorted_values = sorted(numeric_values)
                        if sorted_values[0] != sorted_values[-1]:
                            trend_direction = "ä¸Šå‡" if sorted_values[-1] > sorted_values[0] else "ä¸‹é™"
                            trends[f"{col_name}_trend"] = {
                                'direction': trend_direction,
                                'range': f"{sorted_values[0]} - {sorted_values[-1]}",
                                'variation': sorted_values[-1] - sorted_values[0]
                            }
                except Exception:
                    continue
                    
        except Exception as e:
            print(f"âš ï¸ è¶‹åŠ¿åˆ†æå¤±è´¥: {e}")
        
        return trends
    
    def analyze_data_relationships(self, rows: List[Tuple], column_names: List[str]) -> Dict:
        """åˆ†ææ•°æ®å…³è”å…³ç³»"""
        if not rows or not column_names:
            return {}
        
        relationships = {}
        try:
            # åˆ†æå¤–é”®å…³ç³»
            for table_name, rels in self.schema_analyzer.table_relationships.items():
                for rel in rels:
                    relationships[f"{table_name}.{rel['column']}"] = {
                        'references': f"{rel['foreign_table']}.{rel['foreign_column']}",
                        'type': 'foreign_key'
                    }
            
            # åˆ†ææ•°æ®ä¸­çš„å…³è”æ¨¡å¼
            data_dict = {}
            for i, col_name in enumerate(column_names):
                data_dict[col_name] = [row[i] for row in rows]
            
            # æŸ¥æ‰¾å¯èƒ½çš„å…³è”åˆ—ï¼ˆç›¸åŒå€¼çš„åˆ—ï¼‰
            for col1 in column_names:
                for col2 in column_names:
                    if col1 != col2:
                        try:
                            values1 = set(str(data_dict[col1][i]) for i in range(len(rows)) if data_dict[col1][i] is not None)
                            values2 = set(str(data_dict[col2][i]) for i in range(len(rows)) if data_dict[col2][i] is not None)
                            
                            # è®¡ç®—é‡å åº¦
                            overlap = len(values1.intersection(values2))
                            if overlap > 0 and len(values1) > 0 and len(values2) > 0:
                                overlap_ratio = overlap / min(len(values1), len(values2))
                                if overlap_ratio > 0.3:  # 30%ä»¥ä¸Šé‡å è®¤ä¸ºæœ‰å…³è”
                                    relationships[f"{col1}_vs_{col2}"] = {
                                        'overlap_count': overlap,
                                        'overlap_ratio': overlap_ratio,
                                        'type': 'data_overlap'
                                    }
                        except Exception:
                            continue
        
        except Exception as e:
            print(f"âš ï¸ å…³è”å…³ç³»åˆ†æå¤±è´¥: {e}")
        
        return relationships
    

    
    def query(self, question: str, context: str = "") -> str:
        """é€šç”¨æ•°æ®åº“æŸ¥è¯¢æ¥å£ - ç›´æ¥æ‰§è¡ŒæŸ¥è¯¢å¹¶è¿”å›å…·ä½“æ•°æ®"""
        try:
            print(f"ğŸ” å¼€å§‹å¤„ç†æŸ¥è¯¢: {question}")
            
            # 1. æ™ºèƒ½ç”ŸæˆSQLæŸ¥è¯¢
            sql = self._generate_intelligent_sql(question)
            
            if not sql:
                print("âŒ SQLç”Ÿæˆå¤±è´¥")
                return "æ— æ³•ç†è§£æŸ¥è¯¢éœ€æ±‚ï¼Œè¯·æä¾›æ›´å…·ä½“çš„é—®é¢˜"
            
            print(f"âœ… ç”Ÿæˆçš„SQL: {sql}")
            
            # 2. æ‰§è¡ŒæŸ¥è¯¢
            rows = self.execute_query(sql)
            
            if not rows:
                print("âŒ æŸ¥è¯¢è¿”å›ç©ºç»“æœ")
                return "æœªæ‰¾åˆ°ç›¸å…³æ•°æ®ï¼Œè¯·æ£€æŸ¥æŸ¥è¯¢æ¡ä»¶"
            
            print(f"âœ… æŸ¥è¯¢æˆåŠŸï¼Œè¿”å› {len(rows)} æ¡è®°å½•")
            
            # 3. è·å–åˆ—å
            column_names = self.get_column_names(sql)
            if not column_names:
                column_names = [f"column_{i}" for i in range(len(rows[0]) if rows else 0)]
            
            print(f"âœ… åˆ—å: {column_names}")
            
            # 4. ç›´æ¥è¿”å›å…·ä½“æ•°æ®å’Œåˆ†æ
            result = self._format_comprehensive_results(question, rows, column_names, sql)
            print(f"âœ… ç»“æœæ ¼å¼åŒ–å®Œæˆï¼Œé•¿åº¦: {len(result)} å­—ç¬¦")
            
            return result
            
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return f"æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {str(e)}"
    
    def _generate_intelligent_sql(self, question: str) -> Optional[str]:
        """æ™ºèƒ½ç”ŸæˆSQLæŸ¥è¯¢ - ä½¿ç”¨æ„å›¾åˆ†æ"""
        try:
            print(f"ğŸ§  å¼€å§‹æ™ºèƒ½SQLç”Ÿæˆï¼Œé—®é¢˜: {question}")
            
            # ä½¿ç”¨æ–°çš„æ„å›¾åˆ†æåŠŸèƒ½
            return self.generate_sql(question)
            
        except Exception as e:
            print(f"âŒ æ™ºèƒ½SQLç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def execute_query_with_columns(self, sql: str):
        """æ‰§è¡ŒSQLå¹¶è¿”å› (rows, column_names)"""
        try:
            print(f"ğŸš€ æ‰§è¡ŒSQLæŸ¥è¯¢: {repr(sql)}")
            print(f"SQLç±»å‹: {type(sql)}")
            assert self.conn and self.conn.closed == 0, "æ•°æ®åº“è¿æ¥å·²å…³é—­"
            cursor = self.conn.cursor()
            cursor.execute(sql)
            rows = cursor.fetchall()
            column_names = [desc[0] for desc in cursor.description]
            cursor.close()
            print(f"âœ… æŸ¥è¯¢æ‰§è¡ŒæˆåŠŸï¼Œè¿”å› {len(rows)} è¡Œæ•°æ®")
            return rows, column_names
        except Exception as e:
            print(f"âŒ SQLæ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            with open("sql_error.log", "a", encoding="utf-8") as f:
                f.write(f"SQLæ‰§è¡Œå¤±è´¥: {repr(sql)}\\né”™è¯¯: {e}\\n")
            return [], []
    
    def get_column_names(self, sql: str) -> List[str]:
        """è·å–æŸ¥è¯¢ç»“æœçš„åˆ—å"""
        try:
            print(f"ğŸ“‹ è·å–åˆ—åï¼ŒSQL: {sql}")
            cursor = self.conn.cursor()
            cursor.execute(sql)
            column_names = [desc[0] for desc in cursor.description]
            cursor.close()
            print(f"âœ… è·å–åˆ—åæˆåŠŸ: {column_names}")
            return column_names
        except Exception as e:
            print(f"âŒ è·å–åˆ—åå¤±è´¥: {e}")
            return []
    
    def analyze_data_statistics(self, rows: List[Tuple], column_names: List[str]) -> Dict:
        """åˆ†ææ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
        if not rows or not column_names:
            return {}
        
        stats = {}
        try:
            # è½¬æ¢ä¸ºDataFrameæ ¼å¼è¿›è¡Œåˆ†æ
            data_dict = {}
            for i, col_name in enumerate(column_names):
                data_dict[col_name] = [row[i] for row in rows]
            
            # æ•°å€¼å‹åˆ—ç»Ÿè®¡
            numeric_stats = {}
            for col_name, values in data_dict.items():
                try:
                    # å°è¯•è½¬æ¢ä¸ºæ•°å€¼
                    numeric_values = []
                    for val in values:
                        if val is not None:
                            try:
                                numeric_values.append(float(val))
                            except (ValueError, TypeError):
                                continue
                    
                    if numeric_values:
                        numeric_stats[col_name] = {
                            'count': len(numeric_values),
                            'sum': sum(values),
                            'avg': sum(values) / len(values),
                            'min': min(values),
                            'max': max(values)
                        }
                except Exception:
                    continue
            
            # åˆ†ç±»åˆ—ç»Ÿè®¡
            categorical_stats = {}
            for col_name, values in data_dict.items():
                if col_name not in numeric_stats:
                    try:
                        value_counts = {}
                        for val in values:
                            if val is not None:
                                val_str = str(val)
                                value_counts[val_str] = value_counts.get(val_str, 0) + 1
                        
                        if value_counts:
                            categorical_stats[col_name] = {
                                'unique_count': len(value_counts),
                                'top_values': sorted(value_counts.items(), key=lambda x: x[1], reverse=True)[:5]
                            }
                    except Exception:
                        continue
            
            stats = {
                'total_rows': len(rows),
                'numeric_columns': numeric_stats,
                'categorical_columns': categorical_stats
            }
            
        except Exception as e:
            print(f"âš ï¸ æ•°æ®ç»Ÿè®¡åˆ†æå¤±è´¥: {e}")
        
        return stats
    
    def analyze_data_trends(self, rows: List[Tuple], column_names: List[str]) -> Dict:
        """åˆ†ææ•°æ®è¶‹åŠ¿"""
        if not rows or not column_names:
            return {}
        
        trends = {}
        try:
            # æŸ¥æ‰¾æ—¶é—´ç›¸å…³åˆ—
            time_columns = []
            for col_name in column_names:
                if any(keyword in col_name.lower() for keyword in ['time', 'date', 'created', 'updated', 'timestamp']):
                    time_columns.append(col_name)
            
            if time_columns:
                # åˆ†ææ—¶é—´è¶‹åŠ¿
                for time_col in time_columns:
                    try:
                        time_idx = column_names.index(time_col)
                        time_values = [row[time_idx] for row in rows if row[time_idx] is not None]
                        
                        if time_values:
                            # ç®€å•çš„æ—¶é—´è¶‹åŠ¿åˆ†æ
                            trends[time_col] = {
                                'earliest': min(time_values),
                                'latest': max(time_values),
                                'total_periods': len(time_values)
                            }
                    except Exception:
                        continue
            
            # åˆ†ææ•°å€¼è¶‹åŠ¿
            data_dict = {}
            for i, col_name in enumerate(column_names):
                data_dict[col_name] = [row[i] for row in rows]
            
            for col_name, values in data_dict.items():
                try:
                    numeric_values = []
                    for val in values:
                        if val is not None:
                            try:
                                numeric_values.append(float(val))
                            except (ValueError, TypeError):
                                continue
                    
                    if len(numeric_values) > 1:
                        # è®¡ç®—è¶‹åŠ¿ï¼ˆç®€å•çº¿æ€§è¶‹åŠ¿ï¼‰
                        sorted_values = sorted(numeric_values)
                        if sorted_values[0] != sorted_values[-1]:
                            trend_direction = "ä¸Šå‡" if sorted_values[-1] > sorted_values[0] else "ä¸‹é™"
                            trends[f"{col_name}_trend"] = {
                                'direction': trend_direction,
                                'range': f"{sorted_values[0]} - {sorted_values[-1]}",
                                'variation': sorted_values[-1] - sorted_values[0]
                            }
                except Exception:
                    continue
                    
        except Exception as e:
            print(f"âš ï¸ è¶‹åŠ¿åˆ†æå¤±è´¥: {e}")
        
        return trends
    
    def analyze_data_relationships(self, rows: List[Tuple], column_names: List[str]) -> Dict:
        """åˆ†ææ•°æ®å…³è”å…³ç³»"""
        if not rows or not column_names:
            return {}
        
        relationships = {}
        try:
            # åˆ†æå¤–é”®å…³ç³»
            for table_name, rels in self.schema_analyzer.table_relationships.items():
                for rel in rels:
                    relationships[f"{table_name}.{rel['column']}"] = {
                        'references': f"{rel['foreign_table']}.{rel['foreign_column']}",
                        'type': 'foreign_key'
                    }
            
            # åˆ†ææ•°æ®ä¸­çš„å…³è”æ¨¡å¼
            data_dict = {}
            for i, col_name in enumerate(column_names):
                data_dict[col_name] = [row[i] for row in rows]
            
            # æŸ¥æ‰¾å¯èƒ½çš„å…³è”åˆ—ï¼ˆç›¸åŒå€¼çš„åˆ—ï¼‰
            for col1 in column_names:
                for col2 in column_names:
                    if col1 != col2:
                        try:
                            values1 = set(str(data_dict[col1][i]) for i in range(len(rows)) if data_dict[col1][i] is not None)
                            values2 = set(str(data_dict[col2][i]) for i in range(len(rows)) if data_dict[col2][i] is not None)
                            
                            # è®¡ç®—é‡å åº¦
                            overlap = len(values1.intersection(values2))
                            if overlap > 0 and len(values1) > 0 and len(values2) > 0:
                                overlap_ratio = overlap / min(len(values1), len(values2))
                                if overlap_ratio > 0.3:  # 30%ä»¥ä¸Šé‡å è®¤ä¸ºæœ‰å…³è”
                                    relationships[f"{col1}_vs_{col2}"] = {
                                        'overlap_count': overlap,
                                        'overlap_ratio': overlap_ratio,
                                        'type': 'data_overlap'
                                    }
                        except Exception:
                            continue
        
        except Exception as e:
            print(f"âš ï¸ å…³è”å…³ç³»åˆ†æå¤±è´¥: {e}")
        
        return relationships
    

    
    def _format_comprehensive_results(self, question: str, rows: List[Tuple], column_names: List[str], sql: str) -> str:
        """ç»¼åˆæ ¼å¼åŒ–æŸ¥è¯¢ç»“æœï¼Œè¿”å›å…·ä½“æ•°æ®"""
        try:
            result = f"ğŸ“Š æŸ¥è¯¢ç»“æœï¼šå…±æ‰¾åˆ° {len(rows)} æ¡è®°å½•\n\n"
            
            # 1. æ˜¾ç¤ºè¡¨å¤´
            result += "ğŸ“‹ æ•°æ®æ˜ç»†ï¼š\n"
            result += " | ".join(f"{name:<15}" for name in column_names) + "\n"
            result += "-" * (len(column_names) * 18) + "\n"
            
            # 2. æ˜¾ç¤ºæ•°æ®ï¼ˆæœ€å¤šæ˜¾ç¤º15è¡Œï¼‰
            for i, row in enumerate(rows[:15]):
                formatted_row = []
                for value in row:
                    if value is None:
                        formatted_row.append("NULL".ljust(15))
                    else:
                        str_value = str(value)
                        if len(str_value) > 15:
                            str_value = str_value[:12] + "..."
                        formatted_row.append(str_value.ljust(15))
                result += " | ".join(formatted_row) + "\n"
            
            if len(rows) > 15:
                result += f"... è¿˜æœ‰ {len(rows) - 15} æ¡è®°å½•\n"
            
            # 3. æ·»åŠ ç»Ÿè®¡åˆ†æ
            result += "\nğŸ“ˆ ç»Ÿè®¡åˆ†æï¼š\n"
            
            # æ•°å€¼åˆ—ç»Ÿè®¡
            numeric_stats = self._calculate_numeric_stats(rows, column_names)
            if numeric_stats:
                result += "æ•°å€¼ç»Ÿè®¡ï¼š\n"
                for col, stats in numeric_stats.items():
                    result += f"  {col}: æ€»è®¡{stats['sum']:,.2f}, å¹³å‡{stats['avg']:.2f}, èŒƒå›´{stats['min']}-{stats['max']}\n"
            
            # åˆ†ç±»ç»Ÿè®¡
            categorical_stats = self._calculate_categorical_stats(rows, column_names)
            if categorical_stats:
                result += "\nåˆ†ç±»ç»Ÿè®¡ï¼š\n"
                for col, stats in categorical_stats.items():
                    result += f"  {col}: {stats['unique_count']}ä¸ªä¸åŒå€¼\n"
                    if stats['top_values']:
                        top_val = stats['top_values'][0]
                        result += f"    æœ€å¸¸è§: {top_val[0]} ({top_val[1]}æ¬¡)\n"
            
            # 4. ä¸šåŠ¡æ´å¯Ÿ
            result += "\nğŸ’¡ ä¸šåŠ¡æ´å¯Ÿï¼š\n"
            insight = self._generate_comprehensive_insight(question, rows, column_names, sql)
            result += insight
            
            # 5. æ•°æ®æ‘˜è¦
            result += "\nğŸ“‹ æ•°æ®æ‘˜è¦ï¼š\n"
            result += f"â€¢ æŸ¥è¯¢å­—æ®µï¼š{', '.join(column_names)}\n"
            result += f"â€¢ æ•°æ®æ—¶é—´ï¼šæœ€æ–°è®°å½•åŒ…å«{len(rows)}æ¡æ•°æ®\n"
            result += f"â€¢ æŸ¥è¯¢ç±»å‹ï¼š{self._identify_query_type(question)}\n"
            
            return result
            
        except Exception as e:
            return f"ç»“æœæ ¼å¼åŒ–å¤±è´¥: {str(e)}"
    
    def _calculate_numeric_stats(self, rows: List[Tuple], column_names: List[str]) -> Dict:
        """è®¡ç®—æ•°å€¼åˆ—ç»Ÿè®¡"""
        stats = {}
        for i, col_name in enumerate(column_names):
            try:
                values = []
                for row in rows:
                    if row[i] is not None:
                        try:
                            values.append(float(row[i]))
                        except (ValueError, TypeError):
                            continue
                
                if values:
                    stats[col_name] = {
                        'count': len(values),
                        'sum': sum(values),
                        'avg': sum(values) / len(values),
                        'min': min(values),
                        'max': max(values)
                    }
            except Exception:
                continue
        return stats
    
    def _calculate_categorical_stats(self, rows: List[Tuple], column_names: List[str]) -> Dict:
        """è®¡ç®—åˆ†ç±»åˆ—ç»Ÿè®¡"""
        stats = {}
        for i, col_name in enumerate(column_names):
            try:
                value_counts = {}
                for row in rows:
                    if row[i] is not None:
                        val_str = str(row[i])
                        value_counts[val_str] = value_counts.get(val_str, 0) + 1
                
                if value_counts:
                    stats[col_name] = {
                        'unique_count': len(value_counts),
                        'top_values': sorted(value_counts.items(), key=lambda x: x[1], reverse=True)[:3]
                    }
            except Exception:
                continue
        return stats
    
    def _identify_query_type(self, question: str) -> str:
        """è¯†åˆ«æŸ¥è¯¢ç±»å‹"""
        if any(keyword in question for keyword in ["é”€å”®", "é”€å”®é¢", "é”€å”®æƒ…å†µ"]):
            return "é”€å”®åˆ†æ"
        elif any(keyword in question for keyword in ["åº“å­˜", "å­˜è´§", "åº“å­˜æƒ…å†µ"]):
            return "åº“å­˜åˆ†æ"
        elif any(keyword in question for keyword in ["äº§å“", "å•†å“", "SKU"]):
            return "äº§å“åˆ†æ"
        elif any(keyword in question for keyword in ["ä»“åº“", "ä»“", "ä¸­å¿ƒä»“"]):
            return "ä»“åº“åˆ†æ"
        elif any(keyword in question for keyword in ["è¶‹åŠ¿", "å˜åŒ–", "å¢é•¿"]):
            return "è¶‹åŠ¿åˆ†æ"
        else:
            return "é€šç”¨æŸ¥è¯¢"
    
    def _generate_comprehensive_insight(self, question: str, rows: List[Tuple], column_names: List[str], sql: str) -> str:
        """ç”Ÿæˆç»¼åˆä¸šåŠ¡æ´å¯Ÿï¼ˆåªè¾“å‡ºä¸€æ¬¡ï¼ŒæŒ‰query_typeåˆ†æµï¼‰"""
        try:
            insight = ""
            query_type = self._identify_query_type(question)
            if query_type == "é”€å”®åˆ†æ":
                insight += self._generate_sales_insight(rows, column_names)
            elif query_type == "åº“å­˜åˆ†æ":
                insight += self._generate_inventory_insight(rows, column_names)
            elif query_type == "äº§å“åˆ†æ":
                insight += self._generate_product_insight(rows, column_names)
            elif query_type == "ä»“åº“åˆ†æ":
                insight += self._generate_warehouse_insight(rows, column_names)
            elif query_type == "è¶‹åŠ¿åˆ†æ":
                insight += self._generate_trend_insight(rows, column_names)
            else:
                insight += self._generate_general_insight(rows, column_names, f"æŸ¥è¯¢è¿”å›{len(rows)}æ¡è®°å½•")
            return insight
        except Exception as e:
            return f"ä¸šåŠ¡æ´å¯Ÿç”Ÿæˆå¤±è´¥: {str(e)}"
    
    def _generate_product_insight(self, rows: List[Tuple], column_names: List[str]) -> str:
        """ç”Ÿæˆäº§å“æ´å¯Ÿ"""
        try:
            insight = ""
            
            # æŸ¥æ‰¾äº§å“ç›¸å…³å­—æ®µ
            product_name_idx = -1
            category_idx = -1
            price_idx = -1
            sales_idx = -1
            
            for i, col in enumerate(column_names):
                if 'product_name' in col.lower() or 'name' in col.lower():
                    product_name_idx = i
                elif 'category' in col.lower():
                    category_idx = i
                elif 'price' in col.lower():
                    price_idx = i
                elif 'sales' in col.lower() or 'amount' in col.lower():
                    sales_idx = i
            
            if product_name_idx >= 0:
                products = set()
                for row in rows:
                    if row[product_name_idx] is not None:
                        products.add(str(row[product_name_idx]))
                insight += f"â€¢ æ¶‰åŠäº§å“ï¼š{len(products)}ç§\n"
                
                if len(products) <= 5:
                    insight += f"â€¢ äº§å“åˆ—è¡¨ï¼š{', '.join(list(products)[:5])}\n"
            
            if category_idx >= 0:
                categories = {}
                for row in rows:
                    if row[category_idx] is not None:
                        cat = str(row[category_idx])
                        categories[cat] = categories.get(cat, 0) + 1
                
                if categories:
                    top_category = max(categories.items(), key=lambda x: x[1])
                    insight += f"â€¢ ä¸»è¦ç±»åˆ«ï¼š{top_category[0]} ({top_category[1]}æ¡è®°å½•)\n"
            
            if sales_idx >= 0:
                total_sales = sum(float(row[sales_idx]) for row in rows if row[sales_idx] is not None)
                insight += f"â€¢ æ€»é”€å”®é¢ï¼šÂ¥{total_sales:,.2f}\n"
            
            return insight
            
        except Exception as e:
            return f"äº§å“æ´å¯Ÿç”Ÿæˆå¤±è´¥: {str(e)}"
    
    def _generate_warehouse_insight(self, rows: List[Tuple], column_names: List[str]) -> str:
        """ç”Ÿæˆä»“åº“æ´å¯Ÿ"""
        try:
            insight = ""
            
            # æŸ¥æ‰¾ä»“åº“ç›¸å…³å­—æ®µ
            warehouse_name_idx = -1
            inventory_idx = -1
            
            for i, col in enumerate(column_names):
                if 'warehouse' in col.lower():
                    warehouse_name_idx = i
                elif 'inventory' in col.lower() or 'stock' in col.lower():
                    inventory_idx = i
            
            if warehouse_name_idx >= 0:
                warehouses = set()
                for row in rows:
                    if row[warehouse_name_idx] is not None:
                        warehouses.add(str(row[warehouse_name_idx]))
                insight += f"â€¢ æ¶‰åŠä»“åº“ï¼š{len(warehouses)}ä¸ª\n"
                
                if len(warehouses) <= 5:
                    insight += f"â€¢ ä»“åº“åˆ—è¡¨ï¼š{', '.join(list(warehouses)[:5])}\n"
            
            if inventory_idx >= 0:
                total_inventory = sum(float(row[inventory_idx]) for row in rows if row[inventory_idx] is not None)
                insight += f"â€¢ æ€»åº“å­˜é‡ï¼š{total_inventory:,.0f}\n"
            
            return insight
            
        except Exception as e:
            return f"ä»“åº“æ´å¯Ÿç”Ÿæˆå¤±è´¥: {str(e)}"
    
    def _generate_sales_insight(self, rows: List[Tuple], column_names: List[str]) -> str:
        """ç”Ÿæˆé”€å”®æ´å¯Ÿ"""
        try:
            insight = ""
            
            # è®¡ç®—æ€»é”€å”®é¢
            total_sales = 0
            total_quantity = 0
            product_sales = {}
            warehouse_sales = {}
            
            for row in rows:
                amount_idx = column_names.index('total_amount') if 'total_amount' in column_names else -1
                quantity_idx = column_names.index('total_quantity') if 'total_quantity' in column_names else -1
                product_idx = column_names.index('product_name') if 'product_name' in column_names else -1
                warehouse_idx = column_names.index('warehouse_name') if 'warehouse_name' in column_names else -1
                
                if amount_idx >= 0 and row[amount_idx] is not None:
                    total_sales += float(row[amount_idx])
                
                if quantity_idx >= 0 and row[quantity_idx] is not None:
                    total_quantity += float(row[quantity_idx])
                
                if product_idx >= 0 and amount_idx >= 0:
                    product = str(row[product_idx])
                    amount = float(row[amount_idx]) if row[amount_idx] is not None else 0
                    product_sales[product] = product_sales.get(product, 0) + amount
                
                if warehouse_idx >= 0 and amount_idx >= 0:
                    warehouse = str(row[warehouse_idx])
                    amount = float(row[amount_idx]) if row[amount_idx] is not None else 0
                    warehouse_sales[warehouse] = warehouse_sales.get(warehouse, 0) + amount
            
            insight += f"â€¢ æ€»é”€å”®é¢ï¼šÂ¥{total_sales:,.2f}\n"
            insight += f"â€¢ æ€»é”€å”®æ•°é‡ï¼š{total_quantity:,.0f}\n"
            
            if product_sales:
                top_product = max(product_sales.items(), key=lambda x: x[1])
                insight += f"â€¢ çƒ­é”€äº§å“ï¼š{top_product[0]} (Â¥{top_product[1]:,.2f})\n"
            
            if warehouse_sales:
                top_warehouse = max(warehouse_sales.items(), key=lambda x: x[1])
                insight += f"â€¢ é”€å”®æœ€ä½³ä»“åº“ï¼š{top_warehouse[0]} (Â¥{top_warehouse[1]:,.2f})\n"
            
            return insight
            
        except Exception as e:
            return f"é”€å”®æ´å¯Ÿç”Ÿæˆå¤±è´¥: {str(e)}"
    
    def _generate_inventory_insight(self, rows: List[Tuple], column_names: List[str]) -> str:
        """ç”Ÿæˆåº“å­˜æ´å¯Ÿ"""
        try:
            insight = ""
            
            total_value = 0
            low_stock_count = 0
            normal_stock_count = 0
            high_stock_count = 0
            
            for row in rows:
                value_idx = column_names.index('inventory_value') if 'inventory_value' in column_names else -1
                status_idx = column_names.index('stock_status') if 'stock_status' in column_names else -1
                
                if value_idx >= 0 and row[value_idx] is not None:
                    total_value += float(row[value_idx])
                
                if status_idx >= 0:
                    status = str(row[status_idx])
                    if 'éœ€è¦è¡¥è´§' in status:
                        low_stock_count += 1
                    elif 'åº“å­˜å……è¶³' in status:
                        high_stock_count += 1
                    else:
                        normal_stock_count += 1
            
            insight += f"â€¢ æ€»åº“å­˜ä»·å€¼ï¼šÂ¥{total_value:,.2f}\n"
            insight += f"â€¢ éœ€è¦è¡¥è´§ï¼š{low_stock_count}ç§äº§å“\n"
            insight += f"â€¢ åº“å­˜æ­£å¸¸ï¼š{normal_stock_count}ç§äº§å“\n"
            insight += f"â€¢ åº“å­˜å……è¶³ï¼š{high_stock_count}ç§äº§å“\n"
            
            return insight
            
        except Exception as e:
            return f"åº“å­˜æ´å¯Ÿç”Ÿæˆå¤±è´¥: {str(e)}"
    
    def _generate_trend_insight(self, rows: List[Tuple], column_names: List[str]) -> str:
        """ç”Ÿæˆè¶‹åŠ¿æ´å¯Ÿ"""
        try:
            insight = ""
            
            if len(rows) >= 2:
                amount_idx = column_names.index('monthly_sales_amount') if 'monthly_sales_amount' in column_names else -1
                if amount_idx >= 0:
                    current = float(rows[0][amount_idx]) if rows[0][amount_idx] is not None else 0
                    previous = float(rows[1][amount_idx]) if rows[1][amount_idx] is not None else 0
                    
                    if previous > 0:
                        growth = ((current - previous) / previous) * 100
                        insight += f"â€¢ ç¯æ¯”å¢é•¿ç‡ï¼š{growth:+.1f}%\n"
                    
                    insight += f"â€¢ å½“å‰æœˆé”€å”®é¢ï¼šÂ¥{current:,.2f}\n"
                    insight += f"â€¢ ä¸Šæœˆé”€å”®é¢ï¼šÂ¥{previous:,.2f}\n"
            
            return insight
            
        except Exception as e:
            return f"è¶‹åŠ¿æ´å¯Ÿç”Ÿæˆå¤±è´¥: {str(e)}"
    
    def _generate_general_insight(self, rows: List[Tuple], column_names: List[str], data_summary: str) -> str:
        """ç”Ÿæˆé€šç”¨æ´å¯Ÿ"""
        try:
            insight = f"â€¢ {data_summary}\n"
            
            # è®¡ç®—åŸºæœ¬ç»Ÿè®¡
            if rows:
                insight += f"â€¢ æ•°æ®æ—¶é—´èŒƒå›´ï¼šæœ€æ–°è®°å½•åŒ…å«{len(rows)}æ¡æ•°æ®\n"
                
                # æŸ¥æ‰¾å¯èƒ½çš„æ•°å€¼åˆ—è¿›è¡Œç»Ÿè®¡
                numeric_cols = []
                for i, col in enumerate(column_names):
                    try:
                        values = [float(row[i]) for row in rows if row[i] is not None]
                        if values:
                            numeric_cols.append((col, sum(values)))
                    except:
                        continue
                
                if numeric_cols:
                    top_col = max(numeric_cols, key=lambda x: x[1])
                    insight += f"â€¢ ä¸»è¦æ•°å€¼å­—æ®µï¼š{top_col[0]} (æ€»è®¡{top_col[1]:,.2f})\n"
            
            return insight
            
        except Exception as e:
            return f"é€šç”¨æ´å¯Ÿç”Ÿæˆå¤±è´¥: {str(e)}"
    
    def get_database_summary(self) -> str:
        """è·å–æ•°æ®åº“æ•´ä½“æ‘˜è¦"""
        try:
            summary = []
            summary.append(f"æ•°æ®åº“è¿æ¥ï¼š{Config.DB_HOST}:{Config.DB_PORT}/{Config.DB_NAME}")
            summary.append(f"è¡¨æ•°é‡ï¼š{len(self.schema_analyzer.schema_info)}")
            
            # ç»Ÿè®¡æ¯ä¸ªè¡¨çš„æ•°æ®é‡
            for table_name in self.schema_analyzer.schema_info.keys():
                try:
                    cursor = self.conn.cursor()
                    cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
                    count = cursor.fetchone()[0]
                    cursor.close()
                    summary.append(f"  {table_name}: {count} æ¡è®°å½•")
                except Exception:
                    summary.append(f"  {table_name}: æ— æ³•è·å–è®°å½•æ•°")
            
            return "\n".join(summary)
        except Exception as e:
            return f"æ•°æ®åº“æ‘˜è¦è·å–å¤±è´¥: {str(e)}"
    
    def close(self):
        self.conn.close()

    def build_sql_from_intent(self, intent: Dict) -> str:
        """æ ¹æ®æ„å›¾ç»“æ„è‡ªåŠ¨ç”ŸæˆSQLï¼Œåˆå¹¶æ‰€æœ‰SQLç”Ÿæˆé€»è¾‘"""
        query_type = intent.get("query_type", "ç»¼åˆæŸ¥è¯¢")
        filter_conditions = intent.get("filter_conditions", {})
        aggregation = intent.get("aggregation", {})
        order_by = aggregation.get("order_by", [])
        columns = intent.get("target_columns") or []
        # åªæŸ¥productè¡¨çš„ç®€å•æŸ¥è¯¢
        if query_type == "äº§å“åˆ†æ" and (not columns or set(columns) <= {"product_id","product_name","category","unit_price","cost_price","barcode"}):
            sql = """
            SELECT p.product_id, p.product_name, p.category, p.unit_price, p.cost_price, p.barcode
            FROM product p
            WHERE 1=1
            """
            if filter_conditions.get("category"):
                sql += f" AND p.category = '{filter_conditions['category']}'"
            if filter_conditions.get("product_name"):
                sql += f" AND p.product_name LIKE '%{filter_conditions['product_name']}%'"
            sql += " ORDER BY p.unit_price ASC LIMIT 20"
            return textwrap.dedent(sql)
        # å¤æ‚äº§å“åˆ†æï¼ˆå¸¦èšåˆï¼‰
        if query_type == "äº§å“åˆ†æ":
            sql = """
            SELECT 
                p.product_id,
                p.product_name,
                p.category,
                p.unit_price,
                p.cost_price,
                p.barcode,
                COALESCE(SUM(s.quantity), 0) as total_sales_quantity,
                COALESCE(SUM(s.total_amount), 0) as total_sales_amount,
                COALESCE(SUM(wi.quantity), 0) as total_warehouse_stock,
                COALESCE(SUM(si.stock_quantity), 0) as total_store_stock
            FROM product p
            LEFT JOIN sales s ON p.product_id = s.product_id
            LEFT JOIN warehouse_inventory wi ON p.product_id = wi.product_id
            LEFT JOIN store_inventory si ON p.product_id = si.product_id
            WHERE 1=1
            """
            if filter_conditions.get("category"):
                sql += f" AND p.category = '{filter_conditions['category']}'"
            if filter_conditions.get("product_name"):
                sql += f" AND p.product_name LIKE '%{filter_conditions['product_name']}%'"
            sql += " GROUP BY p.product_id, p.product_name, p.category, p.unit_price, p.cost_price, p.barcode"
            if "unit_price DESC" in order_by:
                sql += " ORDER BY p.unit_price DESC"
            elif "unit_price ASC" in order_by:
                sql += " ORDER BY p.unit_price ASC"
            elif "total_sales_quantity DESC" in order_by:
                sql += " ORDER BY total_sales_quantity DESC"
            elif "total_sales_amount DESC" in order_by:
                sql += " ORDER BY total_sales_amount DESC"
            else:
                sql += " ORDER BY p.product_name"
            sql += " LIMIT 20"
            return textwrap.dedent(sql)
        # å…¶å®ƒç±»å‹ï¼Œè°ƒç”¨åŸæœ‰ç”Ÿæˆæ–¹æ³•
        return self.generate_sql_from_intent(intent)

    def execute_query(self, sql: str) -> List[Tuple]:
        try:
            print(f"ğŸš€ æ‰§è¡ŒSQLæŸ¥è¯¢: {repr(sql)}")
            print(f"SQLç±»å‹: {type(sql)}")
            assert self.conn and self.conn.closed == 0, "æ•°æ®åº“è¿æ¥å·²å…³é—­"
            cursor = self.conn.cursor()
            cursor.execute(sql)
            rows = cursor.fetchall()
            cursor.close()
            print(f"âœ… æŸ¥è¯¢æ‰§è¡ŒæˆåŠŸï¼Œè¿”å› {len(rows)} è¡Œæ•°æ®")
            return rows
        except Exception as e:
            print(f"âŒ SQLæ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            with open("sql_error.log", "a", encoding="utf-8") as f:
                f.write(f"SQLæ‰§è¡Œå¤±è´¥: {repr(sql)}\\né”™è¯¯: {e}\\n")
            return []

    def query(self, question: str, context: str = "") -> str:
        """ä¸»å…¥å£ï¼šæ¥æ”¶ç”¨æˆ·é—®é¢˜ï¼Œè¿”å›ç›´è§‚åŒ–ä¸šåŠ¡æ•°æ®å’Œåˆ†æï¼Œä¸æ˜¾ç¤ºSQL"""
        # 1. æ„å›¾è¯†åˆ«
        intent = self.analyze_query_intent(question)
        print(f"âœ… æŸ¥è¯¢æ„å›¾åˆ†æå®Œæˆ: {intent}")

        # 2. SQLç”Ÿæˆ
        sql = self.build_sql_from_intent(intent)
        print(f"ğŸ”§ åŸºäºæ„å›¾ç”ŸæˆSQL: {intent}")  # ä»…æ—¥å¿—ï¼Œä¸è¾“å‡ºSQLå†…å®¹

        # 3. SQLæ‰§è¡Œ
        rows, column_names = self.execute_query_with_columns(sql)
        if rows:
            # 4. ä¸šåŠ¡æ´å¯Ÿä¸ç›´è§‚åŒ–è¾“å‡º
            answer = self._format_query_result(rows, column_names)
            insight = self._generate_comprehensive_insight(question, rows, column_names, sql)
            return f"{answer}\n{insight}"
        else:
            # 5. æ•°æ®ä¸ºç©ºæ—¶æ‰è€ƒè™‘çŸ¥è¯†åº“/LLMè¡¥å……
            kb_result = self.query_knowledge_base(question)
            return f"æœªæŸ¥è¯¢åˆ°ç›¸å…³æ•°æ®åº“æ•°æ®ã€‚\n{kb_result}"

    def _format_query_result(self, rows, column_names):
        """å°†æ•°æ®åº“æŸ¥è¯¢ç»“æœæ ¼å¼åŒ–ä¸ºç»“æ„åŒ–è¡¨æ ¼æˆ–ç›´è§‚æ–‡æœ¬"""
        if not rows or not column_names:
            return "æœªæŸ¥è¯¢åˆ°ç›¸å…³æ•°æ®ã€‚"
        # ç®€å•è¡¨æ ¼è¾“å‡º
        from tabulate import tabulate
        table = tabulate(rows, headers=column_names, tablefmt="fancy_grid", floatfmt=".2f")
        return f"\nğŸ“Š æŸ¥è¯¢ç»“æœ\n{table}\n"