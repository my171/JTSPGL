'''
    TopAgent - ä½œä¸ºä¸­æ¢å¤§è„‘ï¼Œè´Ÿè´£ç†è§£ã€åˆ†æå’ŒAgentåè°ƒ
'''

import os
import re
import json
import numpy as np
from config import Config
from typing import List, Dict
from langchain.schema import Document
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain_huggingface import HuggingFaceEmbeddings

from API_TextToText.API_of_RAG._6_MemoryAgent import MemoryAgent

class TopAgent:
    def __init__(self, memory_agent: MemoryAgent, db_agent, pdf_agent, kb):
        self.memory_agent = memory_agent
        self.db_agent = db_agent
        self.pdf_agent = pdf_agent
        self.kb = kb
        self.llm = ChatOpenAI(
            model_name=Config.RAG_MODEL_NAME,
            openai_api_key=Config.RAG_OPENAI_API_KEY,
            openai_api_base=Config.RAG_OPENAI_API_URL,
            temperature=0.3
        )
        # åˆå§‹åŒ–è¯­ä¹‰æ£€ç´¢ç»„ä»¶
        self.embeddings = HuggingFaceEmbeddings(model_name = Config.RAG_EMBEDDING_MODEL)
        self.candidate_examples = self._initialize_candidate_examples()
        self.candidate_vectors = None
        self._build_candidate_vectors()
    
    def _initialize_candidate_examples(self) -> List[Dict]:
        """åˆå§‹åŒ–å€™é€‰ç¤ºä¾‹åº“"""
        examples = [
            {
                "task": "åº“å­˜åˆ†æ",
                "examples": [
                    "åˆ†æåº“å­˜ç‰©å“çš„ABCåˆ†ç±»",
                    "è®¡ç®—åº“å­˜å‘¨è½¬ç‡",
                    "è¯†åˆ«æ»é”€å•†å“",
                    "åˆ†æåº“å­˜ç»“æ„",
                    "è¯„ä¼°åº“å­˜æˆæœ¬"
                ]
            },
            {
                "task": "ä»“å‚¨è§„åˆ’",
                "examples": [
                    "ä¼˜åŒ–å­˜å‚¨ç­–ç•¥",
                    "è®¾è®¡è´§æ¶å¸ƒå±€",
                    "è§„åˆ’ä»“å‚¨ç©ºé—´",
                    "ç¡®å®šå­˜å‚¨ä½ç½®",
                    "åˆ†æå­˜å‚¨æ•ˆç‡"
                ]
            },
            {
                "task": "è®¢å•ç®¡ç†",
                "examples": [
                    "åˆ†æè®¢å•è¶‹åŠ¿",
                    "å¤„ç†è®¢å•å¼‚å¸¸",
                    "ä¼˜åŒ–è®¢å•æµç¨‹",
                    "ç»Ÿè®¡è®¢å•æ•°æ®",
                    "é¢„æµ‹è®¢å•é‡"
                ]
            },
            {
                "task": "ä¾›åº”é“¾åˆ†æ",
                "examples": [
                    "åˆ†æä¾›åº”å•†ç»©æ•ˆ",
                    "è¯„ä¼°ä¾›åº”é“¾é£é™©",
                    "ä¼˜åŒ–é‡‡è´­ç­–ç•¥",
                    "ç›‘æ§ä¾›åº”é“¾çŠ¶æ€",
                    "åˆ†æç‰©æµæˆæœ¬"
                ]
            },
            {
                "task": "æ•°æ®æŸ¥è¯¢",
                "examples": [
                    "æŸ¥è¯¢å•†å“ä¿¡æ¯",
                    "ç»Ÿè®¡é”€å”®æ•°æ®",
                    "åˆ†æå®¢æˆ·è¡Œä¸º",
                    "æŸ¥çœ‹åº“å­˜çŠ¶æ€",
                    "å¯¼å‡ºæŠ¥è¡¨æ•°æ®"
                ]
            }
        ]
        return examples
    def _build_candidate_vectors(self):
        """ç¦»çº¿æ„å»ºå€™é€‰ç¤ºä¾‹çš„å‘é‡è¡¨å¾"""
        try:
            all_examples = []
            for task_group in self.candidate_examples:
                for example in task_group["examples"]:
                    all_examples.append({
                        "text": example,
                        "task": task_group["task"],
                        "full_text": f"{task_group['task']}: {example}"
                    })
            # æ‰¹é‡ç”Ÿæˆå‘é‡è¡¨å¾
            texts = [item["full_text"] for item in all_examples]
            vectors = self.embeddings.embed_documents(texts)
            # å­˜å‚¨å‘é‡å’Œå…ƒæ•°æ®
            self.candidate_vectors = []
            for i, (item, vector) in enumerate(zip(all_examples, vectors)):
                self.candidate_vectors.append({
                    "id": i,
                    "text": item["text"],
                    "task": item["task"],
                    "full_text": item["full_text"],
                    "vector": vector
                })
            
            print(f"âœ… æˆåŠŸæ„å»º {len(self.candidate_vectors)} ä¸ªå€™é€‰ç¤ºä¾‹çš„å‘é‡è¡¨å¾")
        except Exception as e:
            print(f"âŒ å€™é€‰ç¤ºä¾‹å‘é‡æ„å»ºå¤±è´¥: {e}")
            self.candidate_vectors = []
    
    def _calculate_semantic_similarity(self, query_vector, candidate_vector) -> float:
        """è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦ï¼‰"""
        try:
            query_np = np.array(query_vector)
            candidate_np = np.array(candidate_vector)
            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            dot_product = np.dot(query_np, candidate_np)
            query_norm = np.linalg.norm(query_np)
            candidate_norm = np.linalg.norm(candidate_np)
            if query_norm == 0 or candidate_norm == 0:
                return 0.0
            
            similarity = dot_product / (query_norm * candidate_norm)
            return float(similarity)
            
        except Exception as e:
            print(f"âš ï¸ ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    def _knn_semantic_search(self, query: str, k: int = 5) -> List[Dict]:
        """åŸºäºKNNçš„è¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢"""
        if not self.candidate_vectors:
            return []
        try:
            # å®æ—¶è¡¨å¾ç”¨æˆ·è¾“å…¥
            query_vector = self.embeddings.embed_query(query)
            # è®¡ç®—ä¸æ‰€æœ‰å€™é€‰ç¤ºä¾‹çš„ç›¸ä¼¼åº¦
            similarities = []
            for candidate in self.candidate_vectors:
                similarity = self._calculate_semantic_similarity(query_vector, candidate["vector"])
                similarities.append({
                    "candidate": candidate,
                    "similarity": similarity
                })
            
            # æŒ‰ç›¸ä¼¼åº¦æ’åºï¼Œå–å‰kä¸ª
            similarities.sort(key=lambda x: x["similarity"], reverse=True)
            top_k_results = similarities[:k]
            
            return top_k_results
        except Exception as e:
            print(f"âš ï¸ KNNè¯­ä¹‰æ£€ç´¢å¤±è´¥: {e}")
            return []
    def _enhance_query_with_semantic_context(self, query: str) -> str:
        """åŸºäºè¯­ä¹‰æ£€ç´¢å¢å¼ºæŸ¥è¯¢ä¸Šä¸‹æ–‡"""
        semantic_results = self._knn_semantic_search(query, k=3)
        
        if not semantic_results:
            return query
        # æ„å»ºè¯­ä¹‰ä¸Šä¸‹æ–‡
        context_parts = []
        for i, result in enumerate(semantic_results):
            candidate = result["candidate"]
            similarity = result["similarity"]
            if similarity > 0.5:  # åªä½¿ç”¨ç›¸ä¼¼åº¦è¾ƒé«˜çš„ç»“æœ
                context_parts.append(f"ç›¸å…³ä»»åŠ¡{i+1}: {candidate['task']} - {candidate['text']} (ç›¸ä¼¼åº¦: {similarity:.2f})")
        
        if context_parts:
            semantic_context = "\n".join(context_parts)
            enhanced_query = f"ç”¨æˆ·é—®é¢˜: {query}\n\nè¯­ä¹‰ç›¸å…³ä»»åŠ¡:\n{semantic_context}"
            return enhanced_query
        
        return query
    
    def analyze_query_intent(self, question: str, context: str = "") -> Dict:
        """åˆ†ææŸ¥è¯¢æ„å›¾ï¼Œå†³å®šéœ€è¦å“ªäº›Agentå‚ä¸"""
        try:
            intent_prompt = PromptTemplate.from_template("""
åˆ†æç”¨æˆ·é—®é¢˜çš„æ„å›¾ï¼Œå†³å®šéœ€è¦å“ªäº›ä¸“ä¸šAgentæ¥å›ç­”ï¼š

ç”¨æˆ·é—®é¢˜ï¼š{question}
å¯¹è¯ä¸Šä¸‹æ–‡ï¼š{context}

è¯·åˆ†æé—®é¢˜ç±»å‹ï¼Œå¹¶è¿”å›JSONæ ¼å¼çš„å†³ç­–ï¼š
{{
    "requires_database": true/false,  // æ˜¯å¦éœ€è¦æ•°æ®åº“æŸ¥è¯¢
    "requires_pdf": true/false,       // æ˜¯å¦éœ€è¦PDFæ£€ç´¢
    "requires_knowledge_base": true/false,  // æ˜¯å¦éœ€è¦çŸ¥è¯†åº“æ£€ç´¢
    "primary_agent": "database/pdf/knowledge_base/multi",  // ä¸»è¦Agent
    "reasoning": "åˆ†æç†ç”±"
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
""")
            
            response = self.llm.invoke(intent_prompt.format(
                question=question,
                context=context
            ))
            
            # è§£æJSONå“åº”
            intent_data = json.loads(response.content.strip())
            return intent_data
            
        except Exception as e:
            #(f"âš ï¸ æ„å›¾åˆ†æå¤±è´¥: {e}")
            # é»˜è®¤è¿”å›å¤šAgentæ¨¡å¼
            return {
                "requires_database": True,
                "requires_pdf": True,
                "requires_knowledge_base": True,
                "primary_agent": "multi",
                "reasoning": "é»˜è®¤å¤šAgentæ¨¡å¼"
            }
    
    def coordinate_agents(self, question: str, context: str = "") -> Dict:
        """åè°ƒå„ä¸ªAgentï¼Œè·å–ç»¼åˆå›ç­”"""
        # 1. è¯­ä¹‰æ£€ç´¢å¢å¼º
        enhanced_question = self._enhance_query_with_semantic_context(question)
        semantic_results = self._knn_semantic_search(question, k=3)
        
        # æ£€æŸ¥æœ€é«˜ç›¸å…³æ€§
        max_similarity = max([r['similarity'] for r in semantic_results], default=0)
        
        # 2. åˆ†ææŸ¥è¯¢æ„å›¾
        try:
            intent = self.analyze_query_intent(enhanced_question, context)
        except Exception as e:
            print(f"âš ï¸ æ„å›¾åˆ†æå¤±è´¥: {e}")
            intent = None
        
        # å¦‚æœæ„å›¾åˆ†æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥
        if not intent or not isinstance(intent, dict) or not intent.get('primary_agent'):
            intent = {
                "requires_database": True,
                "requires_pdf": True,
                "requires_knowledge_base": True,
                "primary_agent": "multi",
                "reasoning": "é»˜è®¤å¤šAgentåè°ƒæ¨¡å¼"
            }
        
        # 3. ä¼˜å…ˆæ‰§è¡Œæ•°æ®åº“æŸ¥è¯¢
        results = {}
        db_result = ""
        
        # æ•°æ®åº“æŸ¥è¯¢ï¼ˆä¼˜å…ˆæ‰§è¡Œï¼‰
        if intent.get("requires_database", True):
            try:
                print("ğŸ” ä¼˜å…ˆæ‰§è¡Œæ•°æ®åº“æŸ¥è¯¢...")
                # ç›´æ¥æ‰§è¡Œæ•°æ®åº“æŸ¥è¯¢
                db_result = self.db_agent.query(question, context)
                
                # æ£€æŸ¥æ•°æ®åº“æŸ¥è¯¢æ˜¯å¦æˆåŠŸè¿”å›å…·ä½“æ•°æ®
                if db_result and "æœªæ‰¾åˆ°ç›¸å…³æ•°æ®" not in db_result and "æ— æ³•ç†è§£æŸ¥è¯¢éœ€æ±‚" not in db_result:
                    results["db_result"] = db_result
                    print("âœ… æ•°æ®åº“æŸ¥è¯¢æˆåŠŸï¼Œè¿”å›å…·ä½“æ•°æ®")
                else:
                    print("âš ï¸ æ•°æ®åº“æŸ¥è¯¢æœªè¿”å›å…·ä½“æ•°æ®")
                    results["db_result"] = "æ•°æ®åº“æŸ¥è¯¢æœªè¿”å›å…·ä½“æ•°æ®"
                    
                # è·å–æ•°æ®åº“æ‘˜è¦ä¿¡æ¯
                try:
                    db_summary = self.db_agent.get_database_summary()
                    results["db_summary"] = db_summary
                except Exception:
                    pass
                    
            except Exception as e:
                print(f"âŒ æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {e}")
                results["db_result"] = f"æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {e}"
        
        # 4. å¦‚æœæ•°æ®åº“æŸ¥è¯¢æˆåŠŸè¿”å›å…·ä½“æ•°æ®ï¼Œç›´æ¥åŸºäºæ•°æ®ç”Ÿæˆå›ç­”
        if results.get("db_result") and "æœªæ‰¾åˆ°ç›¸å…³æ•°æ®" not in results["db_result"] and "æ— æ³•ç†è§£æŸ¥è¯¢éœ€æ±‚" not in results["db_result"]:
            print("ğŸ¯ åŸºäºæ•°æ®åº“å…·ä½“æ•°æ®ç”Ÿæˆå›ç­”...")
            
            # çŸ¥è¯†åº“æŸ¥è¯¢ï¼ˆä½œä¸ºè¡¥å……ï¼‰
            if intent.get("requires_knowledge_base", True):
                try:
                    if hasattr(self.kb, 'query_with_database_context'):
                        results["knowledge_context"] = self.kb.query_with_database_context(question)
                    else:
                        docs = self.kb.vectorstore.similarity_search(question, k=3)
                        results["knowledge_context"] = self._format_knowledge_context(docs)
                except Exception as e:
                    results["knowledge_context"] = f"çŸ¥è¯†åº“æ£€ç´¢å¤±è´¥: {e}"
            
            # PDFæŸ¥è¯¢ï¼ˆä½œä¸ºè¡¥å……ï¼‰
            if intent.get("requires_pdf", True):
                try:
                    results["pdf_result"] = self.pdf_agent.query(question)
                except Exception as e:
                    results["pdf_result"] = f"PDFæ£€ç´¢å¤±è´¥: {e}"
            
            # åŸºäºæ•°æ®åº“å…·ä½“æ•°æ®ç”Ÿæˆæ™ºèƒ½å›ç­”
            final_answer = self._generate_data_driven_answer(question, results, intent, semantic_results)
            
            return {
                "answer": final_answer,
                "knowledge_context": results.get("knowledge_context", ""),
                "db_result": results.get("db_result", ""),
                "pdf_result": results.get("pdf_result", ""),
                "db_summary": results.get("db_summary", ""),
                "source_type": "database_driven",
                "confidence": min(0.95, 0.8 + max_similarity * 0.15),
                "agent_decision": intent,
                "semantic_results": semantic_results
            }
        
        # 5. å¦‚æœæ•°æ®åº“æŸ¥è¯¢å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿå¤šAgentæ¨¡å¼
        print("ğŸ”„ ä½¿ç”¨ä¼ ç»Ÿå¤šAgentåè°ƒæ¨¡å¼...")
        
        # çŸ¥è¯†åº“æŸ¥è¯¢
        if intent.get("requires_knowledge_base", True):
            try:
                if hasattr(self.kb, 'query_with_database_context'):
                    results["knowledge_context"] = self.kb.query_with_database_context(question)
                else:
                    docs = self.kb.vectorstore.similarity_search(question, k=5)
                    results["knowledge_context"] = self._format_knowledge_context(docs)
            except Exception as e:
                results["knowledge_context"] = f"çŸ¥è¯†åº“æ£€ç´¢å¤±è´¥: {e}"
        
        # PDFæŸ¥è¯¢
        if intent.get("requires_pdf", True):
            try:
                results["pdf_result"] = self.pdf_agent.query(question)
            except Exception as e:
                results["pdf_result"] = f"PDFæ£€ç´¢å¤±è´¥: {e}"
        
        # æ™ºèƒ½ç»“æœæ•´åˆ
        final_answer = self._generate_intelligent_answer(question, results, intent, semantic_results)
        
        return {
            "answer": final_answer,
            "knowledge_context": results.get("knowledge_context", ""),
            "db_result": results.get("db_result", ""),
            "pdf_result": results.get("pdf_result", ""),
            "db_summary": results.get("db_summary", ""),
            "source_type": "top_agent_coordinated",
            "confidence": min(0.9, 0.7 + max_similarity * 0.2),
            "agent_decision": intent,
            "semantic_results": semantic_results
        }
    
    def _generate_data_driven_answer(self, question: str, results: Dict, intent: Dict, semantic_results: List) -> str:
        """åŸºäºæ•°æ®åº“å…·ä½“æ•°æ®ç”Ÿæˆå›ç­”"""
        try:
            # æ„å»ºæ•°æ®é©±åŠ¨çš„å›ç­”
            data_prompt = PromptTemplate.from_template("""
ä½œä¸ºæ™ºèƒ½ä»“å‚¨ç³»ç»Ÿçš„æ•°æ®åˆ†æä¸“å®¶ï¼Œè¯·åŸºäºä»¥ä¸‹æ•°æ®åº“å…·ä½“æ•°æ®ï¼Œä¸ºç”¨æˆ·é—®é¢˜æä¾›ç›´æ¥ã€å‡†ç¡®ã€æ•°æ®é©±åŠ¨çš„å›ç­”ï¼š

ç”¨æˆ·é—®é¢˜ï¼š{question}

ã€æ•°æ®åº“å…·ä½“æ•°æ®ã€‘
{db_result}

ã€çŸ¥è¯†åº“è¡¥å……ä¿¡æ¯ã€‘
{knowledge_context}

ã€PDFè¡¥å……ä¿¡æ¯ã€‘
{pdf_result}

è¯·æä¾›ï¼š
1. ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜ï¼ŒåŸºäºæ•°æ®åº“å…·ä½“æ•°æ®
2. æ•°æ®åˆ†æå’Œä¸šåŠ¡æ´å¯Ÿ
3. å…·ä½“çš„æ•°å€¼å’Œç»Ÿè®¡ä¿¡æ¯
4. åŸºäºæ•°æ®çš„å»ºè®®

è¦æ±‚ï¼š
- å›ç­”è¦åŸºäºæ•°æ®åº“çš„å…·ä½“æ•°æ®ï¼Œä¸è¦ç»™å‡ºSQLå»ºè®®
- çªå‡ºå…³é”®æ•°æ®å’Œç»Ÿè®¡ä¿¡æ¯
- æä¾›æ•°æ®é©±åŠ¨çš„ä¸šåŠ¡æ´å¯Ÿ
- å›ç­”è¦ç®€æ´ã€ä¸“ä¸šã€å‡†ç¡®

åŸºäºæ•°æ®çš„å›ç­”ï¼š
""")
            
            response = self.llm.invoke(data_prompt.format(
                question=question,
                db_result=results.get("db_result", "æ— æ•°æ®åº“æ•°æ®"),
                knowledge_context=results.get("knowledge_context", "æ— çŸ¥è¯†åº“ä¿¡æ¯"),
                pdf_result=results.get("pdf_result", "æ— PDFä¿¡æ¯")
            ))
            
            return response.content.strip()
            
        except Exception as e:
            return f"æ•°æ®é©±åŠ¨å›ç­”ç”Ÿæˆå¤±è´¥: {str(e)}"
    
    def _format_knowledge_context(self, docs: List[Document]) -> str:
        """æ ¼å¼åŒ–çŸ¥è¯†åº“ä¸Šä¸‹æ–‡ï¼Œè§£å†³å¤šè¡Œéš”æ–­é—®é¢˜"""
        if not docs:
            return ""
        
        formatted_contexts = []
        for i, doc in enumerate(docs[:3]):  # åªå–å‰3ä¸ªæœ€ç›¸å…³çš„
            content = doc.page_content.strip()
            # æ¸…ç†å’Œæ ¼å¼åŒ–æ–‡æœ¬
            content = re.sub(r'\n+', ' ', content)  # å°†å¤šä¸ªæ¢è¡Œç¬¦æ›¿æ¢ä¸ºç©ºæ ¼
            content = re.sub(r'\s+', ' ', content)  # å°†å¤šä¸ªç©ºæ ¼æ›¿æ¢ä¸ºå•ä¸ªç©ºæ ¼
            content = content[:300] + "..." if len(content) > 300 else content
            formatted_contexts.append(f"çŸ¥è¯†ç‰‡æ®µ{i+1}: {content}")
        
        return "\n".join(formatted_contexts)
    
    def _generate_intelligent_answer(self, question: str, results: Dict, intent: Dict, semantic_results: List) -> str:
        """æ™ºèƒ½ç”Ÿæˆç»¼åˆå›ç­”"""
        try:
            # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
            context_parts = []
            
            # æ·»åŠ è¯­ä¹‰ç›¸å…³ä»»åŠ¡ä¿¡æ¯
            if semantic_results:
                relevant_tasks = []
                for result in semantic_results[:2]:  # å–å‰2ä¸ªæœ€ç›¸å…³çš„
                    if result['similarity'] > 0.4:
                        candidate = result['candidate']
                        relevant_tasks.append(f"{candidate['task']}: {candidate['text']}")
                
                if relevant_tasks:
                    context_parts.append(f"ç›¸å…³ä»»åŠ¡: {'; '.join(relevant_tasks)}")
            
            # æ·»åŠ æ•°æ®åº“æ‘˜è¦
            if results.get("db_summary"):
                context_parts.append(f"æ•°æ®åº“çŠ¶æ€: {results['db_summary']}")
            
            # æ„å»ºç»¼åˆæç¤º
            synthesis_prompt = PromptTemplate.from_template("""
ä½œä¸ºæ™ºèƒ½ä»“å‚¨ç³»ç»Ÿçš„ä¸­æ¢å¤§è„‘ï¼Œè¯·åŸºäºä»¥ä¸‹å¤šæºä¿¡æ¯ç”Ÿæˆä¸“ä¸šã€ç»“æ„åŒ–çš„ç»¼åˆå›ç­”ï¼š

ç”¨æˆ·é—®é¢˜ï¼š{question}
Agentå†³ç­–ï¼š{intent_reasoning}
ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š{context_info}

ã€çŸ¥è¯†åº“ä¿¡æ¯ã€‘
{knowledge_context}

ã€æ•°æ®åº“åˆ†æã€‘
{db_result}

ã€PDFæ£€ç´¢ç»“æœã€‘
{pdf_result}

è¯·æä¾›ï¼š
1. ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜
2. åŸºäºå¤šæºä¿¡æ¯çš„ç»¼åˆåˆ†æ
3. æ•°æ®é©±åŠ¨çš„ä¸šåŠ¡æ´å¯Ÿ
4. å…·ä½“çš„å»ºè®®å’Œä¼˜åŒ–æ–¹å‘
5. å¦‚æœæœ‰ä¸Šä¸‹æ–‡å…³è”ï¼Œè¯·ä½“ç°è¿ç»­æ€§

è¦æ±‚ï¼š
- å›ç­”è¦ç®€æ´ã€ä¸“ä¸šã€ç»“æ„åŒ–
- å……åˆ†åˆ©ç”¨æ•°æ®åº“çš„å…·ä½“æ•°æ®
- ç»“åˆçŸ¥è¯†åº“çš„ç†è®ºæŒ‡å¯¼
- ä½“ç°æ™ºèƒ½åˆ†æèƒ½åŠ›

ç»¼åˆå›ç­”ï¼š
""")
            
            context_info = "\n".join(context_parts) if context_parts else "æ— ç‰¹æ®Šä¸Šä¸‹æ–‡"
            
            response = self.llm.invoke(synthesis_prompt.format(
                question=question,
                intent_reasoning=intent.get("reasoning", ""),
                context_info=context_info,
                knowledge_context=results.get("knowledge_context", "æ— ç›¸å…³ä¿¡æ¯"),
                db_result=results.get("db_result", "æ— æ•°æ®åº“ç»“æœ"),
                pdf_result=results.get("pdf_result", "æ— PDFç»“æœ")
            ))
            
            return response.content.strip()
            
        except Exception as e:
            return f"æ™ºèƒ½å›ç­”ç”Ÿæˆå¤±è´¥: {str(e)}"